{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyO/L4zlMsRF4bBsF/72hb4Z"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **0.0 DATA PROCESSING**"
      ],
      "metadata": {
        "id": "qkMtfHS29wQB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "h4fuIGZJTyAw",
        "outputId": "e25ad09c-8149-4d7c-e225-1d37c8a3a124"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Machine-Learning'...\n",
            "remote: Enumerating objects: 53, done.\u001b[K\n",
            "remote: Counting objects: 100% (53/53), done.\u001b[K\n",
            "remote: Compressing objects: 100% (49/49), done.\u001b[K\n",
            "remote: Total 53 (delta 18), reused 7 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (53/53), 445.02 KiB | 3.53 MiB/s, done.\n",
            "Resolving deltas: 100% (18/18), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/edwinkmusaasizi/Machine-Learning.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd Machine-Learning\n",
        "%cd data\n",
        "%cd interim\n",
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XOq1g9EKBMoS",
        "outputId": "d7baecea-a961-423d-daa0-eb4b656f9795"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Machine-Learning/data/interim/Machine-Learning/data/interim/Machine-Learning\n",
            "/content/Machine-Learning/data/interim/Machine-Learning/data/interim/Machine-Learning/data\n",
            "/content/Machine-Learning/data/interim/Machine-Learning/data/interim/Machine-Learning/data/interim\n",
            "cleaned_mental_health_data.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "0.1 Data Processing"
      ],
      "metadata": {
        "id": "w3CAYEIG383K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "\n",
        "# Load data\n",
        "df = pd.read_csv(\"cleaned_mental_health_data.csv\")\n",
        "\n",
        "# Define adherence labels based on questionnaire responses\n",
        "non_adherence_columns = [\n",
        "    \"Do you ever forget to take your medication?\",\n",
        "    \"Are you careless at times about taking your medication?\",\n",
        "    \"When you feel better, do you sometimes stop taking your medication?\",\n",
        "    \"Sometimes if you feel worse when you take the medication, do you stop taking it?\",\n",
        "    \"I take my medication only when I am sick\"\n",
        "]\n",
        "\n",
        "df[\"adherence\"] = np.where(df[non_adherence_columns].eq(\"Yes\").any(axis=1), 0, 1)\n",
        "\n",
        "# Drop redundant columns\n",
        "df = df.drop(columns=non_adherence_columns + [\"If you have any further comments about medication or this questionnaire, please write them below\"])\n",
        "\n",
        "# Identify all categorical columns\n",
        "categorical_cols = df.select_dtypes(include=['object', 'category']).columns\n",
        "print(\"Categorical columns to encode:\", categorical_cols)\n",
        "\n",
        "# Encode all categorical features\n",
        "for col in categorical_cols:\n",
        "    le = LabelEncoder()\n",
        "    df[col] = le.fit_transform(df[col].astype(str))\n",
        "\n",
        "# Split features and labels\n",
        "X = df.drop(columns=\"adherence\").values\n",
        "y = df[\"adherence\"].values\n",
        "\n",
        "# Split data into train, validation, test (70-15-15)\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, stratify=y_temp, random_state=42)\n",
        "\n",
        "# Apply SMOTE to only the training set\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# Apply SMOTE only to the training data\n",
        "smote = SMOTE(sampling_strategy='auto', random_state=42)\n",
        "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "# Check new class distribution\n",
        "from collections import Counter\n",
        "print(\"New class distribution:\", Counter(y_train_resampled))\n",
        "\n",
        "# Normalize numerical features\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_val = scaler.transform(X_val)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Convert to PyTorch tensors\n",
        "train_dataset = TensorDataset(torch.FloatTensor(X_train), torch.FloatTensor(y_train))\n",
        "val_dataset = TensorDataset(torch.FloatTensor(X_val), torch.FloatTensor(y_val))\n",
        "test_dataset = TensorDataset(torch.FloatTensor(X_test), torch.FloatTensor(y_test))\n",
        "\n",
        "# Create DataLoaders\n",
        "batch_size = 32\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hJM_oZTZ5Kyy",
        "outputId": "faa34c41-1956-4cb8-f378-e9b305947f42"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Categorical columns to encode: Index(['sex', 'Religion', 'marital status', 'education status', 'residence',\n",
            "       'substance use', 'comorbidity',\n",
            "       'It is unnatural for my mind and body to be controlled by medication?',\n",
            "       'My thoughts are clearer on medication',\n",
            "       'By staying on medication, I can prevent getting sick',\n",
            "       'I feel weird, like a ‘zombie’ on medication',\n",
            "       'Medication makes me feel tired and sluggish',\n",
            "       'Some of your symptoms are made by your mind.', 'You are mentally well',\n",
            "       'You do not need medication', 'Your stay in the hospital is necessary',\n",
            "       'The doctor is right in prescribing medication for you.',\n",
            "       'You do not need to be seen by a doctor or psychiatrist',\n",
            "       'If someone said you have a nervous or mental illness, they would be right',\n",
            "       'None of the unusual things you are experiencing are due to an illness.',\n",
            "       '. Loss of energy or drive', 'Feeling unmotivated or numb',\n",
            "       'Daytime sedation or drowsiness', 'Sleeping too much',\n",
            "       'Muscles being too tense or stiff', 'Muscles trembling or shaking',\n",
            "       'Feeling restless or jittery',\n",
            "       'Need to move around and pace; inability to sit still',\n",
            "       'Trouble getting to sleep or staying asleep (insomnia)',\n",
            "       'Blurry vision', 'Dry mouth', 'Drooling',\n",
            "       'Memory and concentration problems', 'Constipation', 'Weight changes',\n",
            "       'Changes in sexual functioning', 'Menstrual or breast problem',\n",
            "       'I feel over burdened by the number of pills i swallow per day.',\n",
            "       'How often do yo take your drugs',\n",
            "       'How often do you find no medications in the hospital',\n",
            "       'I am satisfied with doctors explanation about mental illness and the need for treatment',\n",
            "       'Do you sometimes stop your medications because of religious or cultural beliefs'],\n",
            "      dtype='object')\n",
            "New class distribution: Counter({1: 55, 0: 55})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check class distribution in the training set\n",
        "class_distribution = np.bincount(y_train)\n",
        "print(\"Class Distribution in Training Set:\")\n",
        "print(f\"Class 0 (Non-Adherent): {class_distribution[0]}\")\n",
        "print(f\"Class 1 (Adherent): {class_distribution[1]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uemTnvGF5Wxd",
        "outputId": "178253c5-8b7b-460a-e6e2-edbce8448da9"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class Distribution in Training Set:\n",
            "Class 0 (Non-Adherent): 55\n",
            "Class 1 (Adherent): 26\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implement class weight"
      ],
      "metadata": {
        "id": "zSgD2y_45fQO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Compute class weights\n",
        "class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
        "class_weights = torch.tensor(class_weights, dtype=torch.float32)\n",
        "\n",
        "# Define loss function with class weights\n",
        "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
        "\n",
        "# Example model (Assuming a simple neural network)\n",
        "class AdherenceModel(nn.Module):\n",
        "    def __init__(self, input_size):\n",
        "        super(AdherenceModel, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, 64)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(64, 2)  # Output has 2 classes (0 and 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc2(x)  # No softmax needed for CrossEntropyLoss\n",
        "        return x\n",
        "\n",
        "# Initialize model\n",
        "input_size = X_train.shape[1]  # Number of features\n",
        "model = AdherenceModel(input_size)\n",
        "\n",
        "# Define optimizer\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Training loop (simplified)\n",
        "for epoch in range(10):  # Adjust epochs as needed\n",
        "    model.train()\n",
        "    for batch_X, batch_y in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(batch_X)\n",
        "        batch_y = batch_y.long()  # Convert to long for CrossEntropyLoss\n",
        "        loss = criterion(outputs, batch_y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    print(f\"Epoch {epoch+1}, Loss: {loss.item()}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AlfiL7ZA5ide",
        "outputId": "5b5ed559-5b76-4867-f989-4ce30bd8c9ce"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 0.7398043870925903\n",
            "Epoch 2, Loss: 0.6390100717544556\n",
            "Epoch 3, Loss: 0.6645118594169617\n",
            "Epoch 4, Loss: 0.6223667860031128\n",
            "Epoch 5, Loss: 0.5667624473571777\n",
            "Epoch 6, Loss: 0.5892457365989685\n",
            "Epoch 7, Loss: 0.542084813117981\n",
            "Epoch 8, Loss: 0.5019883513450623\n",
            "Epoch 9, Loss: 0.44666144251823425\n",
            "Epoch 10, Loss: 0.4940347969532013\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "M6xRzM2l5T3k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MODEL 1: DNN"
      ],
      "metadata": {
        "id": "zGOedJj44NEC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **1.0 Teacher Model(DNN)**"
      ],
      "metadata": {
        "id": "MbJ-Zgft991a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.1  Define the Teacher Model Architecture\n",
        "\n"
      ],
      "metadata": {
        "id": "wsi6nwMMANuA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class TeacherModel(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super(TeacherModel, self).__init__()\n",
        "        self.layers = nn.Sequential(\n",
        "            nn.Linear(input_dim, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(256, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layers(x)\n",
        "\n",
        "# Initialize model\n",
        "input_dim = X_train.shape[1]\n",
        "teacher = TeacherModel(input_dim)"
      ],
      "metadata": {
        "id": "6TBz1aVfASdg"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.2 Training Loop"
      ],
      "metadata": {
        "id": "kCV4znXeAX2X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.Adam(teacher.parameters(), lr=0.001)\n",
        "\n",
        "# Early stopping parameters\n",
        "best_val_loss = float('inf')\n",
        "patience = 5\n",
        "counter = 0\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 100\n",
        "for epoch in range(num_epochs):\n",
        "    # Training\n",
        "    teacher.train()\n",
        "    train_loss = 0.0\n",
        "    for inputs, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = teacher(inputs).squeeze()\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "    # Validation\n",
        "    teacher.eval()\n",
        "    val_loss = 0.0\n",
        "    val_preds, val_true = [], []\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in val_loader:\n",
        "            outputs = teacher(inputs).squeeze()\n",
        "            loss = criterion(outputs, labels)\n",
        "            val_loss += loss.item() * inputs.size(0)\n",
        "            val_preds.extend(outputs.numpy())\n",
        "            val_true.extend(labels.numpy())\n",
        "\n",
        "    # Calculate metrics\n",
        "    train_loss = train_loss / len(train_loader.dataset)\n",
        "    val_loss = val_loss / len(val_loader.dataset)\n",
        "    val_auc = roc_auc_score(val_true, val_preds)\n",
        "    val_preds_binary = (np.array(val_preds) > 0.5).astype(int)\n",
        "    val_acc = accuracy_score(val_true, val_preds_binary)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
        "    print(f\"Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f} | Val AUC: {val_auc:.4f} | Val Acc: {val_acc:.4f}\")\n",
        "\n",
        "    # Early stopping\n",
        "    if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss\n",
        "        counter = 0\n",
        "        torch.save(teacher.state_dict(), \"best_teacher.pth\")\n",
        "    else:\n",
        "        counter += 1\n",
        "        if counter >= patience:\n",
        "            print(\"Early stopping!\")\n",
        "            break"
      ],
      "metadata": {
        "id": "KriFvjVWShcd",
        "outputId": "2c862ccb-2459-4a42-fecb-262ded8c0592",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "Train Loss: 0.7056 | Val Loss: 0.6902 | Val AUC: 0.5972 | Val Acc: 0.5556\n",
            "Epoch 2/100\n",
            "Train Loss: 0.6860 | Val Loss: 0.6715 | Val AUC: 0.6806 | Val Acc: 0.6667\n",
            "Epoch 3/100\n",
            "Train Loss: 0.6617 | Val Loss: 0.6473 | Val AUC: 0.7361 | Val Acc: 0.6667\n",
            "Epoch 4/100\n",
            "Train Loss: 0.6270 | Val Loss: 0.6243 | Val AUC: 0.7222 | Val Acc: 0.6667\n",
            "Epoch 5/100\n",
            "Train Loss: 0.5949 | Val Loss: 0.6026 | Val AUC: 0.7083 | Val Acc: 0.6667\n",
            "Epoch 6/100\n",
            "Train Loss: 0.5845 | Val Loss: 0.5887 | Val AUC: 0.7083 | Val Acc: 0.6667\n",
            "Epoch 7/100\n",
            "Train Loss: 0.5534 | Val Loss: 0.5838 | Val AUC: 0.7083 | Val Acc: 0.6667\n",
            "Epoch 8/100\n",
            "Train Loss: 0.5440 | Val Loss: 0.5893 | Val AUC: 0.7222 | Val Acc: 0.6667\n",
            "Epoch 9/100\n",
            "Train Loss: 0.5314 | Val Loss: 0.5998 | Val AUC: 0.7222 | Val Acc: 0.6667\n",
            "Epoch 10/100\n",
            "Train Loss: 0.5234 | Val Loss: 0.6085 | Val AUC: 0.7222 | Val Acc: 0.6667\n",
            "Epoch 11/100\n",
            "Train Loss: 0.4944 | Val Loss: 0.6004 | Val AUC: 0.7222 | Val Acc: 0.6667\n",
            "Epoch 12/100\n",
            "Train Loss: 0.4584 | Val Loss: 0.5930 | Val AUC: 0.7639 | Val Acc: 0.6667\n",
            "Early stopping!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.3 Evaluation"
      ],
      "metadata": {
        "id": "lpAgEnrZSmWT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
        "\n",
        "def calculate_specificity(y_true, y_pred):\n",
        "    \"\"\"Calculate specificity (true negative rate).\"\"\"\n",
        "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
        "    specificity = tn / (tn + fp)\n",
        "    return specificity\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 100\n",
        "for epoch in range(num_epochs):\n",
        "    # Training\n",
        "    teacher.train()\n",
        "    train_loss = 0.0\n",
        "    for inputs, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = teacher(inputs).squeeze()\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "    # Validation\n",
        "    teacher.eval()\n",
        "    val_loss = 0.0\n",
        "    val_preds, val_true = [], []\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in val_loader:\n",
        "            outputs = teacher(inputs).squeeze()\n",
        "            loss = criterion(outputs, labels)\n",
        "            val_loss += loss.item() * inputs.size(0)\n",
        "            val_preds.extend(outputs.numpy())\n",
        "            val_true.extend(labels.numpy())\n",
        "\n",
        "    # Calculate metrics\n",
        "    train_loss = train_loss / len(train_loader.dataset)\n",
        "    val_loss = val_loss / len(val_loader.dataset)\n",
        "\n",
        "    # Convert predictions to binary (0 or 1)\n",
        "    val_preds_binary = (np.array(val_preds) > 0.5).astype(int)\n",
        "\n",
        "    # Calculate precision, recall, F1-score, specificity, and AUC\n",
        "    val_precision = precision_score(val_true, val_preds_binary)\n",
        "    val_recall = recall_score(val_true, val_preds_binary)\n",
        "    val_f1 = f1_score(val_true, val_preds_binary)\n",
        "    val_specificity = calculate_specificity(val_true, val_preds_binary)\n",
        "    val_auc = roc_auc_score(val_true, val_preds)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
        "    print(f\"Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}\")\n",
        "    print(f\"Val Precision: {val_precision:.4f} | Val Recall: {val_recall:.4f}\")\n",
        "    print(f\"Val F1-Score: {val_f1:.4f} | Val Specificity: {val_specificity:.4f}\")\n",
        "    print(f\"Val AUC: {val_auc:.4f}\")\n",
        "\n",
        "    # Early stopping\n",
        "    if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss\n",
        "        counter = 0\n",
        "        torch.save(teacher.state_dict(), \"best_teacher.pth\")\n",
        "    else:\n",
        "        counter += 1\n",
        "        if counter >= patience:\n",
        "            print(\"Early stopping!\")\n",
        "            break\n",
        "\n",
        "print(f\"Learning Rate: {optimizer.param_groups[0]['lr']}\")"
      ],
      "metadata": {
        "id": "LBcGuVmsSs6U",
        "outputId": "bedd4428-1a95-41a5-9152-352953f5c93a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "Train Loss: 0.4705 | Val Loss: 0.5833\n",
            "Val Precision: 0.0000 | Val Recall: 0.0000\n",
            "Val F1-Score: 0.0000 | Val Specificity: 1.0000\n",
            "Val AUC: 0.7361\n",
            "Epoch 2/100\n",
            "Train Loss: 0.4363 | Val Loss: 0.5844\n",
            "Val Precision: 0.0000 | Val Recall: 0.0000\n",
            "Val F1-Score: 0.0000 | Val Specificity: 1.0000\n",
            "Val AUC: 0.7361\n",
            "Epoch 3/100\n",
            "Train Loss: 0.4078 | Val Loss: 0.5961\n",
            "Val Precision: 1.0000 | Val Recall: 0.1667\n",
            "Val F1-Score: 0.2857 | Val Specificity: 1.0000\n",
            "Val AUC: 0.7500\n",
            "Epoch 4/100\n",
            "Train Loss: 0.3858 | Val Loss: 0.6202\n",
            "Val Precision: 1.0000 | Val Recall: 0.1667\n",
            "Val F1-Score: 0.2857 | Val Specificity: 1.0000\n",
            "Val AUC: 0.7500\n",
            "Epoch 5/100\n",
            "Train Loss: 0.3521 | Val Loss: 0.6489\n",
            "Val Precision: 1.0000 | Val Recall: 0.1667\n",
            "Val F1-Score: 0.2857 | Val Specificity: 1.0000\n",
            "Val AUC: 0.7639\n",
            "Epoch 6/100\n",
            "Train Loss: 0.3373 | Val Loss: 0.6927\n",
            "Val Precision: 1.0000 | Val Recall: 0.1667\n",
            "Val F1-Score: 0.2857 | Val Specificity: 1.0000\n",
            "Val AUC: 0.7639\n",
            "Early stopping!\n",
            "Learning Rate: 0.001\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.4 Test Evaluation"
      ],
      "metadata": {
        "id": "Fon2IdccZaOi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the best saved model\n",
        "teacher.load_state_dict(torch.load(\"best_teacher.pth\"))\n",
        "\n",
        "# Test evaluation\n",
        "teacher.eval()\n",
        "test_preds, test_true = [], []\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in test_loader:\n",
        "        outputs = teacher(inputs).squeeze()\n",
        "        test_preds.extend(outputs.numpy())\n",
        "        test_true.extend(labels.numpy())\n",
        "\n",
        "# Convert predictions to binary (0 or 1)\n",
        "test_preds_binary = (np.array(test_preds) > 0.3).astype(int) #lowered the threshold from 0.5 to 0.3\n",
        "\n",
        "# Calculate metrics\n",
        "test_precision = precision_score(test_true, test_preds_binary)\n",
        "test_recall = recall_score(test_true, test_preds_binary)\n",
        "test_f1 = f1_score(test_true, test_preds_binary)\n",
        "test_specificity = calculate_specificity(test_true, test_preds_binary)\n",
        "test_auc = roc_auc_score(test_true, test_preds)\n",
        "\n",
        "print(\"Test Metrics:\")\n",
        "print(f\"Test Precision: {test_precision:.4f} | Test Recall: {test_recall:.4f}\")\n",
        "print(f\"Test F1-Score: {test_f1:.4f} | Test Specificity: {test_specificity:.4f}\")\n",
        "print(f\"Test AUC: {test_auc:.4f}\")"
      ],
      "metadata": {
        "id": "EA7GuVWmZZ3T",
        "outputId": "2830e082-88c5-4292-c595-13a6ebeb1606",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Metrics:\n",
            "Test Precision: 0.2000 | Test Recall: 0.1667\n",
            "Test F1-Score: 0.1818 | Test Specificity: 0.6667\n",
            "Test AUC: 0.4306\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-79-95e920c83986>:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  teacher.load_state_dict(torch.load(\"best_teacher.pth\"))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **2.0 Contrastive Learning**\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "-p_QPB9vcUXx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.1 Data Preparation for Contrastive Learning"
      ],
      "metadata": {
        "id": "1UxfTJuCdUjP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We need to create pairs of samples for contrastive learning. Each pair consists of:\n",
        "\n",
        "Two samples from the same class (positive pair).\n",
        "\n",
        "Two samples from different classes (negative pair)."
      ],
      "metadata": {
        "id": "pfhpzJTadvdp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class ContrastiveDataset(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        x1 = self.X[idx]\n",
        "        y1 = self.y[idx]\n",
        "\n",
        "        # Randomly select a positive or negative pair\n",
        "        if torch.rand(1) > 0.5:\n",
        "            # Positive pair: same class\n",
        "            idx2 = torch.randint(0, len(self.X), (1,)).item()\n",
        "            while self.y[idx2] != y1:\n",
        "                idx2 = torch.randint(0, len(self.X), (1,)).item()\n",
        "            label = 1  # Positive pair label\n",
        "        else:\n",
        "            # Negative pair: different class\n",
        "            idx2 = torch.randint(0, len(self.X), (1,)).item()\n",
        "            while self.y[idx2] == y1:\n",
        "                idx2 = torch.randint(0, len(self.X), (1,)).item()\n",
        "            label = 0  # Negative pair label\n",
        "\n",
        "        x2 = self.X[idx2]\n",
        "        return x1, x2, label\n",
        "\n",
        "# Create contrastive datasets\n",
        "train_contrastive_dataset = ContrastiveDataset(X_train, y_train)\n",
        "val_contrastive_dataset = ContrastiveDataset(X_val, y_val)\n",
        "\n",
        "# Create DataLoaders\n",
        "batch_size = 32\n",
        "train_contrastive_loader = DataLoader(train_contrastive_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_contrastive_loader = DataLoader(val_contrastive_dataset, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "X2RJPUf1djeC"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "23.2 Define the Contrastive Loss"
      ],
      "metadata": {
        "id": "zYi7fKaMdyvp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We’ll use the NT-Xent (Normalized Temperature-Scaled Cross Entropy) loss, which is commonly used in contrastive learning."
      ],
      "metadata": {
        "id": "zvsE2GF5d6na"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "class ContrastiveLoss(nn.Module):\n",
        "    def __init__(self, temperature=0.5):\n",
        "        super(ContrastiveLoss, self).__init__()\n",
        "        self.temperature = temperature\n",
        "\n",
        "    def forward(self, z1, z2, labels):\n",
        "        # Normalize the embeddings\n",
        "        z1 = F.normalize(z1, dim=1)\n",
        "        z2 = F.normalize(z2, dim=1)\n",
        "\n",
        "        # Compute similarity matrix\n",
        "        sim_matrix = torch.matmul(z1, z2.T) / self.temperature\n",
        "\n",
        "        # Positive pairs are on the diagonal\n",
        "        pos_pairs = torch.diag(sim_matrix)\n",
        "\n",
        "        # Negative pairs are off-diagonal\n",
        "        neg_pairs = sim_matrix[~torch.eye(sim_matrix.size(0), dtype=bool)]\n",
        "\n",
        "        # Compute contrastive loss\n",
        "        pos_loss = -torch.log(torch.exp(pos_pairs) / torch.exp(sim_matrix).sum(dim=1))\n",
        "        neg_loss = -torch.log(1 - torch.exp(neg_pairs) / torch.exp(sim_matrix).sum(dim=1))\n",
        "\n",
        "        # Combine losses\n",
        "        loss = (pos_loss.mean() + neg_loss.mean()) / 2\n",
        "        return loss"
      ],
      "metadata": {
        "id": "8cKKGyJjd-iy"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.3  Define the Encoder Model"
      ],
      "metadata": {
        "id": "OTo4lU3SeCeV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The encoder model will learn meaningful representations of the input data. We’ll use a simple feedforward neural network."
      ],
      "metadata": {
        "id": "PAlob6KRfekd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim=128, output_dim=64):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.layers = nn.Sequential(\n",
        "            nn.Linear(input_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, output_dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layers(x)\n",
        "\n",
        "# Initialize encoder\n",
        "input_dim = X_train.shape[1]\n",
        "encoder = Encoder(input_dim)"
      ],
      "metadata": {
        "id": "tr6LLuORffpW"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.4 Training Loop with Contrastive Learning"
      ],
      "metadata": {
        "id": "c6EoZ0LXfvqg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Define ContrastiveDataset\n",
        "class ContrastiveDataset(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.X = torch.FloatTensor(X)  # Convert to FloatTensor\n",
        "        self.y = torch.FloatTensor(y)  # Convert to FloatTensor\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        x1 = self.X[idx]\n",
        "        y1 = self.y[idx]\n",
        "\n",
        "        # Randomly select a positive or negative pair\n",
        "        if torch.rand(1) > 0.5:\n",
        "            # Positive pair: same class\n",
        "            idx2 = torch.randint(0, len(self.X), (1,)).item()\n",
        "            while self.y[idx2] != y1:\n",
        "                idx2 = torch.randint(0, len(self.X), (1,)).item()\n",
        "            label = 1  # Positive pair label\n",
        "        else:\n",
        "            # Negative pair: different class\n",
        "            idx2 = torch.randint(0, len(self.X), (1,)).item()\n",
        "            while self.y[idx2] == y1:\n",
        "                idx2 = torch.randint(0, len(self.X), (1,)).item()\n",
        "            label = 0  # Negative pair label\n",
        "\n",
        "        x2 = self.X[idx2]\n",
        "        return x1, x2, label\n",
        "\n",
        "# Define ContrastiveLoss\n",
        "class ContrastiveLoss(nn.Module):\n",
        "    def __init__(self, temperature=0.5):\n",
        "        super(ContrastiveLoss, self).__init__()\n",
        "        self.temperature = temperature\n",
        "\n",
        "    def forward(self, z1, z2, labels):\n",
        "        # Normalize the embeddings\n",
        "        z1 = F.normalize(z1, dim=1)\n",
        "        z2 = F.normalize(z2, dim=1)\n",
        "\n",
        "        # Compute similarity matrix\n",
        "        sim_matrix = torch.matmul(z1, z2.T) / self.temperature\n",
        "\n",
        "        # Positive pairs are on the diagonal\n",
        "        pos_pairs = torch.diag(sim_matrix)\n",
        "\n",
        "        # Negative pairs are off-diagonal\n",
        "        mask = ~torch.eye(sim_matrix.size(0), dtype=bool, device=sim_matrix.device)\n",
        "        neg_pairs = sim_matrix[mask].reshape(sim_matrix.size(0), -1)\n",
        "\n",
        "        # Compute contrastive loss\n",
        "        pos_loss = -torch.log(torch.exp(pos_pairs) / torch.exp(sim_matrix).sum(dim=1))\n",
        "        neg_loss = -torch.log(1 - torch.exp(neg_pairs) / torch.exp(sim_matrix).sum(dim=1).unsqueeze(1))\n",
        "\n",
        "        # Combine losses\n",
        "        loss = (pos_loss.mean() + neg_loss.mean()) / 2\n",
        "        return loss\n",
        "\n",
        "# Define Encoder\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim=128, output_dim=64):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.layers = nn.Sequential(\n",
        "            nn.Linear(input_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, output_dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layers(x)\n",
        "\n",
        "# Initialize encoder\n",
        "input_dim = X_train.shape[1]\n",
        "encoder = Encoder(input_dim).float()  # Ensure model uses Float\n",
        "\n",
        "# Create contrastive datasets\n",
        "train_contrastive_dataset = ContrastiveDataset(X_train, y_train)\n",
        "val_contrastive_dataset = ContrastiveDataset(X_val, y_val)\n",
        "\n",
        "# Create DataLoaders\n",
        "batch_size = 32\n",
        "train_contrastive_loader = DataLoader(train_contrastive_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
        "val_contrastive_loader = DataLoader(val_contrastive_dataset, batch_size=batch_size, drop_last=True)\n",
        "\n",
        "# Loss and optimizer\n",
        "contrastive_loss = ContrastiveLoss(temperature=0.5)\n",
        "optimizer = optim.Adam(encoder.parameters(), lr=0.001)\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 50\n",
        "for epoch in range(num_epochs):\n",
        "    encoder.train()\n",
        "    train_loss = 0.0\n",
        "    for x1, x2, labels in train_contrastive_loader:\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        z1 = encoder(x1)\n",
        "        z2 = encoder(x2)\n",
        "\n",
        "        # Compute contrastive loss\n",
        "        loss = contrastive_loss(z1, z2, labels)\n",
        "\n",
        "        # Backward pass\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item() * x1.size(0)\n",
        "\n",
        "    # Validation\n",
        "    encoder.eval()\n",
        "    val_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        for x1, x2, labels in val_contrastive_loader:\n",
        "            z1 = encoder(x1)\n",
        "            z2 = encoder(x2)\n",
        "            loss = contrastive_loss(z1, z2, labels)\n",
        "            val_loss += loss.item() * x1.size(0)\n",
        "\n",
        "    # Calculate average losses\n",
        "    train_loss = train_loss / len(train_contrastive_loader.dataset)\n",
        "    val_loss = val_loss / len(val_contrastive_loader.dataset)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
        "    print(f\"Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}\")"
      ],
      "metadata": {
        "id": "jDH5Fu5Hf7jN",
        "outputId": "c65b2637-597b-4eb3-e8a0-1b826e203135",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "Train Loss: 1.4059 | Val Loss: 0.0000\n",
            "Epoch 2/50\n",
            "Train Loss: 1.3944 | Val Loss: 0.0000\n",
            "Epoch 3/50\n",
            "Train Loss: 1.3920 | Val Loss: 0.0000\n",
            "Epoch 4/50\n",
            "Train Loss: 1.4067 | Val Loss: 0.0000\n",
            "Epoch 5/50\n",
            "Train Loss: 1.4016 | Val Loss: 0.0000\n",
            "Epoch 6/50\n",
            "Train Loss: 1.3899 | Val Loss: 0.0000\n",
            "Epoch 7/50\n",
            "Train Loss: 1.3833 | Val Loss: 0.0000\n",
            "Epoch 8/50\n",
            "Train Loss: 1.4039 | Val Loss: 0.0000\n",
            "Epoch 9/50\n",
            "Train Loss: 1.3821 | Val Loss: 0.0000\n",
            "Epoch 10/50\n",
            "Train Loss: 1.3726 | Val Loss: 0.0000\n",
            "Epoch 11/50\n",
            "Train Loss: 1.3912 | Val Loss: 0.0000\n",
            "Epoch 12/50\n",
            "Train Loss: 1.3853 | Val Loss: 0.0000\n",
            "Epoch 13/50\n",
            "Train Loss: 1.3822 | Val Loss: 0.0000\n",
            "Epoch 14/50\n",
            "Train Loss: 1.3827 | Val Loss: 0.0000\n",
            "Epoch 15/50\n",
            "Train Loss: 1.3868 | Val Loss: 0.0000\n",
            "Epoch 16/50\n",
            "Train Loss: 1.3804 | Val Loss: 0.0000\n",
            "Epoch 17/50\n",
            "Train Loss: 1.3834 | Val Loss: 0.0000\n",
            "Epoch 18/50\n",
            "Train Loss: 1.3821 | Val Loss: 0.0000\n",
            "Epoch 19/50\n",
            "Train Loss: 1.3925 | Val Loss: 0.0000\n",
            "Epoch 20/50\n",
            "Train Loss: 1.3913 | Val Loss: 0.0000\n",
            "Epoch 21/50\n",
            "Train Loss: 1.3799 | Val Loss: 0.0000\n",
            "Epoch 22/50\n",
            "Train Loss: 1.3837 | Val Loss: 0.0000\n",
            "Epoch 23/50\n",
            "Train Loss: 1.3810 | Val Loss: 0.0000\n",
            "Epoch 24/50\n",
            "Train Loss: 1.3799 | Val Loss: 0.0000\n",
            "Epoch 25/50\n",
            "Train Loss: 1.3903 | Val Loss: 0.0000\n",
            "Epoch 26/50\n",
            "Train Loss: 1.3913 | Val Loss: 0.0000\n",
            "Epoch 27/50\n",
            "Train Loss: 1.3792 | Val Loss: 0.0000\n",
            "Epoch 28/50\n",
            "Train Loss: 1.3834 | Val Loss: 0.0000\n",
            "Epoch 29/50\n",
            "Train Loss: 1.3821 | Val Loss: 0.0000\n",
            "Epoch 30/50\n",
            "Train Loss: 1.3823 | Val Loss: 0.0000\n",
            "Epoch 31/50\n",
            "Train Loss: 1.3829 | Val Loss: 0.0000\n",
            "Epoch 32/50\n",
            "Train Loss: 1.3865 | Val Loss: 0.0000\n",
            "Epoch 33/50\n",
            "Train Loss: 1.3861 | Val Loss: 0.0000\n",
            "Epoch 34/50\n",
            "Train Loss: 1.3860 | Val Loss: 0.0000\n",
            "Epoch 35/50\n",
            "Train Loss: 1.3826 | Val Loss: 0.0000\n",
            "Epoch 36/50\n",
            "Train Loss: 1.3732 | Val Loss: 0.0000\n",
            "Epoch 37/50\n",
            "Train Loss: 1.3818 | Val Loss: 0.0000\n",
            "Epoch 38/50\n",
            "Train Loss: 1.3833 | Val Loss: 0.0000\n",
            "Epoch 39/50\n",
            "Train Loss: 1.3840 | Val Loss: 0.0000\n",
            "Epoch 40/50\n",
            "Train Loss: 1.3782 | Val Loss: 0.0000\n",
            "Epoch 41/50\n",
            "Train Loss: 1.3851 | Val Loss: 0.0000\n",
            "Epoch 42/50\n",
            "Train Loss: 1.3788 | Val Loss: 0.0000\n",
            "Epoch 43/50\n",
            "Train Loss: 1.3872 | Val Loss: 0.0000\n",
            "Epoch 44/50\n",
            "Train Loss: 1.3830 | Val Loss: 0.0000\n",
            "Epoch 45/50\n",
            "Train Loss: 1.3803 | Val Loss: 0.0000\n",
            "Epoch 46/50\n",
            "Train Loss: 1.3761 | Val Loss: 0.0000\n",
            "Epoch 47/50\n",
            "Train Loss: 1.3801 | Val Loss: 0.0000\n",
            "Epoch 48/50\n",
            "Train Loss: 1.3894 | Val Loss: 0.0000\n",
            "Epoch 49/50\n",
            "Train Loss: 1.3758 | Val Loss: 0.0000\n",
            "Epoch 50/50\n",
            "Train Loss: 1.3831 | Val Loss: 0.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.5 Use Learned Representations\n"
      ],
      "metadata": {
        "id": "btdTcxyuvgth"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract learned representations\n",
        "encoder.eval()\n",
        "with torch.no_grad():\n",
        "    z_train = encoder(torch.FloatTensor(X_train))\n",
        "    z_val = encoder(torch.FloatTensor(X_val))\n",
        "    z_test = encoder(torch.FloatTensor(X_test))"
      ],
      "metadata": {
        "id": "LULIDi4MufqY"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.0 Sparse Knowledge **Distillation**\n",
        "\n",
        "Teacher Model: A large, complex model trained on the dataset (from Step 2).\n",
        "\n",
        "Student Model: A smaller, sparse model that learns from the teacher’s predictions.\n",
        "\n",
        "Knowledge Distillation: The process of transferring knowledge from the teacher to the student.\n",
        "\n",
        "Sparsity: Encouraging the student model to have many zero weights, making it more efficient."
      ],
      "metadata": {
        "id": "r3_4SgIVcKkV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.1 Define the Student Model\n",
        "\n",
        "The student model will be a smaller version of the teacher model. We’ll also add sparsity constraints using L1 regularization."
      ],
      "metadata": {
        "id": "PGfm6YI6cOrx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class StudentModel(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim=64, output_dim=1):\n",
        "        super(StudentModel, self).__init__()\n",
        "        self.layers = nn.Sequential(\n",
        "            nn.Linear(input_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, output_dim),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layers(x)\n",
        "\n",
        "# Initialize student model\n",
        "input_dim = X_train.shape[1]\n",
        "student = StudentModel(input_dim).float()"
      ],
      "metadata": {
        "id": "YN_mGPTTcnQj"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.2Define the Distillation Loss\n",
        "\n",
        "The distillation loss consists of two parts:\n",
        "\n",
        "Cross-Entropy Loss: Measures the difference between the student’s predictions and the true labels.\n",
        "\n",
        "L1 Regularization: Encourages sparsity in the student model."
      ],
      "metadata": {
        "id": "7CsPoVkdc_cn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def distillation_loss(student_outputs, teacher_outputs, labels, alpha=0.5, lambda_l1=0.01):\n",
        "    # Cross-entropy loss (student vs true labels)\n",
        "    ce_loss = F.binary_cross_entropy(student_outputs, labels)\n",
        "\n",
        "    # L1 regularization (encourage sparsity)\n",
        "    l1_loss = 0.0\n",
        "    for param in student.parameters():\n",
        "        l1_loss += torch.norm(param, p=1)\n",
        "\n",
        "    # Combine losses\n",
        "    loss = alpha * ce_loss + (1 - alpha) * F.binary_cross_entropy(student_outputs, teacher_outputs) + lambda_l1 * l1_loss\n",
        "    return loss"
      ],
      "metadata": {
        "id": "VR9hPUfFdpue"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " 3.3 Training Loop for Knowledge Distillation"
      ],
      "metadata": {
        "id": "2-vYFUtEdeuR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the best teacher model\n",
        "teacher.load_state_dict(torch.load(\"best_teacher.pth\"))\n",
        "teacher.eval()\n",
        "\n",
        "# Loss and optimizer for student\n",
        "optimizer_student = optim.Adam(student.parameters(), lr=0.001)\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 50\n",
        "for epoch in range(num_epochs):\n",
        "    student.train()\n",
        "    train_loss = 0.0\n",
        "    for inputs, labels in train_loader:\n",
        "        optimizer_student.zero_grad()\n",
        "\n",
        "        # Forward pass (student)\n",
        "        student_outputs = student(inputs).squeeze()\n",
        "\n",
        "        # Forward pass (teacher)\n",
        "        with torch.no_grad():\n",
        "            teacher_outputs = teacher(inputs).squeeze()\n",
        "\n",
        "        # Compute distillation loss\n",
        "        loss = distillation_loss(student_outputs, teacher_outputs, labels)\n",
        "\n",
        "        # Backward pass\n",
        "        loss.backward()\n",
        "        optimizer_student.step()\n",
        "\n",
        "        train_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "    # Validation\n",
        "    student.eval()\n",
        "    val_loss = 0.0\n",
        "    val_preds, val_true = [], []\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in val_loader:\n",
        "            student_outputs = student(inputs).squeeze()\n",
        "            teacher_outputs = teacher(inputs).squeeze()\n",
        "            loss = distillation_loss(student_outputs, teacher_outputs, labels)\n",
        "            val_loss += loss.item() * inputs.size(0)\n",
        "            val_preds.extend(student_outputs.numpy())\n",
        "            val_true.extend(labels.numpy())\n",
        "\n",
        "    # Calculate average losses\n",
        "    train_loss = train_loss / len(train_loader.dataset)\n",
        "    val_loss = val_loss / len(val_loader.dataset)\n",
        "\n",
        "    # Calculate metrics\n",
        "    val_preds_binary = (np.array(val_preds) > 0.5).astype(int)\n",
        "    val_accuracy = accuracy_score(val_true, val_preds_binary)\n",
        "    val_f1 = f1_score(val_true, val_preds_binary)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
        "    print(f\"Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}\")\n",
        "    print(f\"Val Accuracy: {val_accuracy:.4f} | Val F1-Score: {val_f1:.4f}\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "9JysA8d0d1Bq",
        "outputId": "aa243aa1-5ead-45a4-9d2e-f142f4f95bbf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "Train Loss: 3.2773 | Val Loss: 3.1941\n",
            "Val Accuracy: 0.2778 | Val F1-Score: 0.3810\n",
            "Epoch 2/50\n",
            "Train Loss: 3.1531 | Val Loss: 3.0739\n",
            "Val Accuracy: 0.2778 | Val F1-Score: 0.3158\n",
            "Epoch 3/50\n",
            "Train Loss: 3.0363 | Val Loss: 2.9587\n",
            "Val Accuracy: 0.3333 | Val F1-Score: 0.3333\n",
            "Epoch 4/50\n",
            "Train Loss: 2.9225 | Val Loss: 2.8471\n",
            "Val Accuracy: 0.3889 | Val F1-Score: 0.3529\n",
            "Epoch 5/50\n",
            "Train Loss: 2.8139 | Val Loss: 2.7396\n",
            "Val Accuracy: 0.5000 | Val F1-Score: 0.4000\n",
            "Epoch 6/50\n",
            "Train Loss: 2.7094 | Val Loss: 2.6358\n",
            "Val Accuracy: 0.5556 | Val F1-Score: 0.4286\n",
            "Epoch 7/50\n",
            "Train Loss: 2.6065 | Val Loss: 2.5352\n",
            "Val Accuracy: 0.6111 | Val F1-Score: 0.4615\n",
            "Epoch 8/50\n",
            "Train Loss: 2.5081 | Val Loss: 2.4379\n",
            "Val Accuracy: 0.5000 | Val F1-Score: 0.1818\n",
            "Epoch 9/50\n",
            "Train Loss: 2.4125 | Val Loss: 2.3440\n",
            "Val Accuracy: 0.5000 | Val F1-Score: 0.1818\n",
            "Epoch 10/50\n",
            "Train Loss: 2.3195 | Val Loss: 2.2536\n",
            "Val Accuracy: 0.5556 | Val F1-Score: 0.2000\n",
            "Epoch 11/50\n",
            "Train Loss: 2.2302 | Val Loss: 2.1662\n",
            "Val Accuracy: 0.5556 | Val F1-Score: 0.2000\n",
            "Epoch 12/50\n",
            "Train Loss: 2.1436 | Val Loss: 2.0816\n",
            "Val Accuracy: 0.6111 | Val F1-Score: 0.2222\n",
            "Epoch 13/50\n",
            "Train Loss: 2.0598 | Val Loss: 1.9998\n",
            "Val Accuracy: 0.6111 | Val F1-Score: 0.2222\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-87-e65f4e703bbd>:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  teacher.load_state_dict(torch.load(\"best_teacher.pth\"))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14/50\n",
            "Train Loss: 1.9789 | Val Loss: 1.9211\n",
            "Val Accuracy: 0.6667 | Val F1-Score: 0.2500\n",
            "Epoch 15/50\n",
            "Train Loss: 1.9012 | Val Loss: 1.8450\n",
            "Val Accuracy: 0.6667 | Val F1-Score: 0.2500\n",
            "Epoch 16/50\n",
            "Train Loss: 1.8255 | Val Loss: 1.7715\n",
            "Val Accuracy: 0.6111 | Val F1-Score: 0.0000\n",
            "Epoch 17/50\n",
            "Train Loss: 1.7528 | Val Loss: 1.7007\n",
            "Val Accuracy: 0.6667 | Val F1-Score: 0.0000\n",
            "Epoch 18/50\n",
            "Train Loss: 1.6827 | Val Loss: 1.6317\n",
            "Val Accuracy: 0.6667 | Val F1-Score: 0.0000\n",
            "Epoch 19/50\n",
            "Train Loss: 1.6143 | Val Loss: 1.5659\n",
            "Val Accuracy: 0.6667 | Val F1-Score: 0.0000\n",
            "Epoch 20/50\n",
            "Train Loss: 1.5489 | Val Loss: 1.5025\n",
            "Val Accuracy: 0.6667 | Val F1-Score: 0.0000\n",
            "Epoch 21/50\n",
            "Train Loss: 1.4863 | Val Loss: 1.4421\n",
            "Val Accuracy: 0.6667 | Val F1-Score: 0.0000\n",
            "Epoch 22/50\n",
            "Train Loss: 1.4264 | Val Loss: 1.3848\n",
            "Val Accuracy: 0.6667 | Val F1-Score: 0.0000\n",
            "Epoch 23/50\n",
            "Train Loss: 1.3697 | Val Loss: 1.3297\n",
            "Val Accuracy: 0.6667 | Val F1-Score: 0.0000\n",
            "Epoch 24/50\n",
            "Train Loss: 1.3146 | Val Loss: 1.2767\n",
            "Val Accuracy: 0.6667 | Val F1-Score: 0.0000\n",
            "Epoch 25/50\n",
            "Train Loss: 1.2625 | Val Loss: 1.2258\n",
            "Val Accuracy: 0.6667 | Val F1-Score: 0.0000\n",
            "Epoch 26/50\n",
            "Train Loss: 1.2125 | Val Loss: 1.1775\n",
            "Val Accuracy: 0.6667 | Val F1-Score: 0.0000\n",
            "Epoch 27/50\n",
            "Train Loss: 1.1652 | Val Loss: 1.1324\n",
            "Val Accuracy: 0.6667 | Val F1-Score: 0.0000\n",
            "Epoch 28/50\n",
            "Train Loss: 1.1209 | Val Loss: 1.0899\n",
            "Val Accuracy: 0.6667 | Val F1-Score: 0.0000\n",
            "Epoch 29/50\n",
            "Train Loss: 1.0792 | Val Loss: 1.0497\n",
            "Val Accuracy: 0.6667 | Val F1-Score: 0.0000\n",
            "Epoch 30/50\n",
            "Train Loss: 1.0395 | Val Loss: 1.0117\n",
            "Val Accuracy: 0.6667 | Val F1-Score: 0.0000\n",
            "Epoch 31/50\n",
            "Train Loss: 1.0023 | Val Loss: 0.9754\n",
            "Val Accuracy: 0.6667 | Val F1-Score: 0.0000\n",
            "Epoch 32/50\n",
            "Train Loss: 0.9669 | Val Loss: 0.9417\n",
            "Val Accuracy: 0.6667 | Val F1-Score: 0.0000\n",
            "Epoch 33/50\n",
            "Train Loss: 0.9346 | Val Loss: 0.9100\n",
            "Val Accuracy: 0.6667 | Val F1-Score: 0.0000\n",
            "Epoch 34/50\n",
            "Train Loss: 0.9044 | Val Loss: 0.8806\n",
            "Val Accuracy: 0.6667 | Val F1-Score: 0.0000\n",
            "Epoch 35/50\n",
            "Train Loss: 0.8760 | Val Loss: 0.8529\n",
            "Val Accuracy: 0.6667 | Val F1-Score: 0.0000\n",
            "Epoch 36/50\n",
            "Train Loss: 0.8495 | Val Loss: 0.8277\n",
            "Val Accuracy: 0.6667 | Val F1-Score: 0.0000\n",
            "Epoch 37/50\n",
            "Train Loss: 0.8253 | Val Loss: 0.8048\n",
            "Val Accuracy: 0.6667 | Val F1-Score: 0.0000\n",
            "Epoch 38/50\n",
            "Train Loss: 0.8033 | Val Loss: 0.7838\n",
            "Val Accuracy: 0.6667 | Val F1-Score: 0.0000\n",
            "Epoch 39/50\n",
            "Train Loss: 0.7832 | Val Loss: 0.7653\n",
            "Val Accuracy: 0.6667 | Val F1-Score: 0.0000\n",
            "Epoch 40/50\n",
            "Train Loss: 0.7657 | Val Loss: 0.7493\n",
            "Val Accuracy: 0.6667 | Val F1-Score: 0.0000\n",
            "Epoch 41/50\n",
            "Train Loss: 0.7503 | Val Loss: 0.7353\n",
            "Val Accuracy: 0.6667 | Val F1-Score: 0.0000\n",
            "Epoch 42/50\n",
            "Train Loss: 0.7372 | Val Loss: 0.7237\n",
            "Val Accuracy: 0.6667 | Val F1-Score: 0.0000\n",
            "Epoch 43/50\n",
            "Train Loss: 0.7258 | Val Loss: 0.7134\n",
            "Val Accuracy: 0.6667 | Val F1-Score: 0.0000\n",
            "Epoch 44/50\n",
            "Train Loss: 0.7160 | Val Loss: 0.7053\n",
            "Val Accuracy: 0.6667 | Val F1-Score: 0.0000\n",
            "Epoch 45/50\n",
            "Train Loss: 0.7086 | Val Loss: 0.6998\n",
            "Val Accuracy: 0.6667 | Val F1-Score: 0.0000\n",
            "Epoch 46/50\n",
            "Train Loss: 0.7029 | Val Loss: 0.6953\n",
            "Val Accuracy: 0.6667 | Val F1-Score: 0.0000\n",
            "Epoch 47/50\n",
            "Train Loss: 0.6983 | Val Loss: 0.6910\n",
            "Val Accuracy: 0.6667 | Val F1-Score: 0.0000\n",
            "Epoch 48/50\n",
            "Train Loss: 0.6938 | Val Loss: 0.6870\n",
            "Val Accuracy: 0.6667 | Val F1-Score: 0.0000\n",
            "Epoch 49/50\n",
            "Train Loss: 0.6895 | Val Loss: 0.6839\n",
            "Val Accuracy: 0.6667 | Val F1-Score: 0.0000\n",
            "Epoch 50/50\n",
            "Train Loss: 0.6860 | Val Loss: 0.6811\n",
            "Val Accuracy: 0.6667 | Val F1-Score: 0.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.4 Evaluate the Student Model"
      ],
      "metadata": {
        "id": "KgVl4TMTd-Cq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Test evaluation\n",
        "student.eval()\n",
        "test_preds, test_true = [], []\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in test_loader:\n",
        "        outputs = student(inputs).squeeze()\n",
        "        test_preds.extend(outputs.numpy())\n",
        "        test_true.extend(labels.numpy())\n",
        "\n",
        "# Convert predictions to binary (0 or 1)\n",
        "test_preds_binary = (np.array(test_preds) > 0.5).astype(int)\n",
        "\n",
        "# Calculate metrics\n",
        "test_accuracy = accuracy_score(test_true, test_preds_binary)\n",
        "test_f1 = f1_score(test_true, test_preds_binary)\n",
        "test_precision = precision_score(test_true, test_preds_binary)\n",
        "test_recall = recall_score(test_true, test_preds_binary)\n",
        "\n",
        "print(\"Test Metrics:\")\n",
        "print(f\"Test Accuracy: {test_accuracy:.4f} | Test F1-Score: {test_f1:.4f}\")\n",
        "print(f\"Test Precision: {test_precision:.4f} | Test Recall: {test_recall:.4f}\")"
      ],
      "metadata": {
        "id": "cHzz7ZZYeOuq",
        "outputId": "17c52a43-e538-477b-b2a3-cabf2f71bcc3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Metrics:\n",
            "Test Accuracy: 0.6667 | Test F1-Score: 0.0000\n",
            "Test Precision: 0.0000 | Test Recall: 0.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.5 Sparsity Analysis\n",
        "To analyze the sparsity of the student model, calculate the percentage of zero weights in its parameters."
      ],
      "metadata": {
        "id": "DaFgB70UeU1N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_sparsity(model):\n",
        "    total_params = 0\n",
        "    zero_params = 0\n",
        "    for param in model.parameters():\n",
        "        total_params += param.numel()\n",
        "        zero_params += (param == 0).sum().item()\n",
        "    sparsity = zero_params / total_params\n",
        "    return sparsity\n",
        "\n",
        "# Calculate sparsity\n",
        "sparsity = calculate_sparsity(student)\n",
        "print(f\"Sparsity of Student Model: {sparsity:.4f}\")"
      ],
      "metadata": {
        "id": "IBszZUGpebrS",
        "outputId": "2072aef2-936b-4094-aa2c-0c7a63b4d7f9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sparsity of Student Model: 0.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **4.0 Neuroevolution**"
      ],
      "metadata": {
        "id": "AndCk31zgiPF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4.1 Define the Fitness Function"
      ],
      "metadata": {
        "id": "h4746eEdgpfY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def fitness_function(model, data_loader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in data_loader:\n",
        "            outputs = model(inputs).squeeze()\n",
        "            preds = (outputs > 0.5).float()\n",
        "            correct += (preds == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "    accuracy = correct / total\n",
        "\n",
        "    # Calculate sparsity\n",
        "    sparsity = calculate_sparsity(model)\n",
        "\n",
        "    # Combine accuracy and sparsity into a single fitness score\n",
        "    fitness = accuracy + sparsity\n",
        "    return fitness"
      ],
      "metadata": {
        "id": "dIg4uy-phw9F"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4.2 Define the Evolutionary Algorithm\n",
        "\n",
        "We’ll use a simple genetic algorithm to evolve the student model. The algorithm consists of the following steps:\n",
        "\n",
        "Initialize Population: Create a population of candidate models with random architectures.\n",
        "\n",
        "Evaluate Fitness: Evaluate the fitness of each candidate model.\n",
        "\n",
        "Selection: Select the best-performing models to create the next generation.\n",
        "\n",
        "Mutation and Crossover: Generate new candidate models by mutating and crossing over the selected models.\n",
        "\n",
        "Repeat: Repeat the process for a fixed number of generations."
      ],
      "metadata": {
        "id": "n5oMChBfhwZ9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "# Define mutation and crossover functions\n",
        "def mutate(model):\n",
        "    for param in model.parameters():\n",
        "        if random.random() < 0.1:  # Mutation probability\n",
        "            param.data += torch.randn_like(param.data) * 0.1  # Add random noise\n",
        "    return model\n",
        "\n",
        "def crossover(model1, model2):\n",
        "    child = StudentModel(input_dim).float()\n",
        "    for param1, param2, param_child in zip(model1.parameters(), model2.parameters(), child.parameters()):\n",
        "        if random.random() < 0.5:  # Crossover probability\n",
        "            param_child.data = param1.data\n",
        "        else:\n",
        "            param_child.data = param2.data\n",
        "    return child\n",
        "\n",
        "# Initialize population\n",
        "population_size = 10\n",
        "population = [StudentModel(input_dim).float() for _ in range(population_size)]\n",
        "\n",
        "# Evolutionary algorithm\n",
        "num_generations = 20\n",
        "for generation in range(num_generations):\n",
        "    print(f\"Generation {generation+1}/{num_generations}\")\n",
        "\n",
        "    # Evaluate fitness of each individual\n",
        "    fitness_scores = []\n",
        "    for model in population:\n",
        "        fitness = fitness_function(model, val_loader)\n",
        "        fitness_scores.append(fitness)\n",
        "\n",
        "    # Sort population based on fitness scores\n",
        "    sorted_indices = sorted(range(len(fitness_scores)), key=lambda i: fitness_scores[i], reverse=True)\n",
        "    sorted_population = [population[i] for i in sorted_indices]\n",
        "\n",
        "    # Select top-performing individuals\n",
        "    top_models = sorted_population[:5]  # Select top 5 models\n",
        "\n",
        "    # Create next generation\n",
        "    next_generation = top_models.copy()  # Keep top models\n",
        "    while len(next_generation) < population_size:\n",
        "        parent1, parent2 = random.sample(top_models, 2)  # Select two parents\n",
        "        child = crossover(parent1, parent2)  # Create child\n",
        "        child = mutate(child)  # Mutate child\n",
        "        next_generation.append(child)\n",
        "\n",
        "    # Update population\n",
        "    population = next_generation\n",
        "\n",
        "# Select the best model from the final population\n",
        "best_model = max(population, key=lambda model: fitness_function(model, val_loader))"
      ],
      "metadata": {
        "id": "DPUVFfVfiC8E",
        "outputId": "a23bf034-12d8-4bed-da82-ac7ea3dfc44c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generation 1/20\n",
            "Generation 2/20\n",
            "Generation 3/20\n",
            "Generation 4/20\n",
            "Generation 5/20\n",
            "Generation 6/20\n",
            "Generation 7/20\n",
            "Generation 8/20\n",
            "Generation 9/20\n",
            "Generation 10/20\n",
            "Generation 11/20\n",
            "Generation 12/20\n",
            "Generation 13/20\n",
            "Generation 14/20\n",
            "Generation 15/20\n",
            "Generation 16/20\n",
            "Generation 17/20\n",
            "Generation 18/20\n",
            "Generation 19/20\n",
            "Generation 20/20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4.3 Evaluate the Best Model"
      ],
      "metadata": {
        "id": "WHbm9pYvoFUi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Test evaluation\n",
        "best_model.eval()\n",
        "test_preds, test_true = [], []\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in test_loader:\n",
        "        outputs = best_model(inputs).squeeze()\n",
        "        test_preds.extend(outputs.numpy())\n",
        "        test_true.extend(labels.numpy())\n",
        "\n",
        "# Convert predictions to binary (0 or 1)\n",
        "test_preds_binary = (np.array(test_preds) > 0.5).astype(int)\n",
        "\n",
        "# Calculate metrics\n",
        "test_accuracy = accuracy_score(test_true, test_preds_binary)\n",
        "test_f1 = f1_score(test_true, test_preds_binary)\n",
        "test_precision = precision_score(test_true, test_preds_binary)\n",
        "test_recall = recall_score(test_true, test_preds_binary)\n",
        "\n",
        "print(\"Test Metrics for Best Model:\")\n",
        "print(f\"Test Accuracy: {test_accuracy:.4f} | Test F1-Score: {test_f1:.4f}\")\n",
        "print(f\"Test Precision: {test_precision:.4f} | Test Recall: {test_recall:.4f}\")\n",
        "\n",
        "# Calculate sparsity\n",
        "sparsity = calculate_sparsity(best_model)\n",
        "print(f\"Sparsity of Best Model: {sparsity:.4f}\")"
      ],
      "metadata": {
        "id": "Kq90ySSRoI2U",
        "outputId": "22e9b348-dd5b-4f65-c9d1-dc7f981dfbf8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Metrics for Best Model:\n",
            "Test Accuracy: 0.3889 | Test F1-Score: 0.1538\n",
            "Test Precision: 0.1429 | Test Recall: 0.1667\n",
            "Sparsity of Best Model: 0.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.0 Evaluation\n",
        "\n",
        "Evaluate the final sparse student model on the test set using metrics such as:\n",
        "\n",
        "Accuracy\n",
        "\n",
        "Precision, Recall, F1-score\n",
        "\n",
        "ROC-AUC"
      ],
      "metadata": {
        "id": "778Qs50Wovc2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "5.1 Evaluate best model"
      ],
      "metadata": {
        "id": "TVgHk0kVo3GP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix, roc_curve, auc\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Test evaluation\n",
        "best_model.eval()\n",
        "test_preds, test_true = [], []\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in test_loader:\n",
        "        outputs = best_model(inputs).squeeze()\n",
        "        test_preds.extend(outputs.numpy())\n",
        "        test_true.extend(labels.numpy())\n",
        "\n",
        "# Convert predictions to binary (0 or 1)\n",
        "test_preds_binary = (np.array(test_preds) > 0.5).astype(int)\n",
        "\n",
        "# Calculate metrics\n",
        "test_accuracy = accuracy_score(test_true, test_preds_binary)\n",
        "test_f1 = f1_score(test_true, test_preds_binary)\n",
        "test_precision = precision_score(test_true, test_preds_binary)\n",
        "test_recall = recall_score(test_true, test_preds_binary)\n",
        "\n",
        "print(\"Test Metrics for Best Model:\")\n",
        "print(f\"Test Accuracy: {test_accuracy:.4f} | Test F1-Score: {test_f1:.4f}\")\n",
        "print(f\"Test Precision: {test_precision:.4f} | Test Recall: {test_recall:.4f}\")\n",
        "\n",
        "# Calculate sparsity\n",
        "def calculate_sparsity(model):\n",
        "    total_params = 0\n",
        "    zero_params = 0\n",
        "    for param in model.parameters():\n",
        "        total_params += param.numel()\n",
        "        zero_params += (param == 0).sum().item()\n",
        "    sparsity = zero_params / total_params\n",
        "    return sparsity\n",
        "\n",
        "sparsity = calculate_sparsity(best_model)\n",
        "print(f\"Sparsity of Best Model: {sparsity:.4f}\")\n",
        "\n",
        "# Generate confusion matrix\n",
        "cm = confusion_matrix(test_true, test_preds_binary)\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[\"Non-Adherent\", \"Adherent\"], yticklabels=[\"Non-Adherent\", \"Adherent\"])\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"True\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()\n",
        "\n",
        "# Compute ROC curve\n",
        "fpr, tpr, thresholds = roc_curve(test_true, test_preds)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "# Plot ROC curve\n",
        "plt.figure()\n",
        "plt.plot(fpr, tpr, color=\"darkorange\", lw=2, label=f\"ROC curve (area = {roc_auc:.2f})\")\n",
        "plt.plot([0, 1], [0, 1], color=\"navy\", lw=2, linestyle=\"--\")\n",
        "plt.xlabel(\"False Positive Rate\")\n",
        "plt.ylabel(\"True Positive Rate\")\n",
        "plt.title(\"Receiver Operating Characteristic (ROC) Curve\")\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "f7uWLUXwqsFJ",
        "outputId": "0ed225d2-6309-44b6-9a8c-cf62ea488673",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 996
        }
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Metrics for Best Model:\n",
            "Test Accuracy: 0.3889 | Test F1-Score: 0.1538\n",
            "Test Precision: 0.1429 | Test Recall: 0.1667\n",
            "Sparsity of Best Model: 0.0000\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MODEL 2: XGBOOST"
      ],
      "metadata": {
        "id": "8036nwn-4eT4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Implementation\n"
      ],
      "metadata": {
        "id": "xWBe69b2JTSi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Processing & SMOTE Application"
      ],
      "metadata": {
        "id": "OMwhCSwLJY26"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "# Load data\n",
        "df = pd.read_csv(\"cleaned_mental_health_data.csv\")\n",
        "\n",
        "# Define adherence labels based on questionnaire responses\n",
        "non_adherence_columns = [\n",
        "    \"Do you ever forget to take your medication?\",\n",
        "    \"Are you careless at times about taking your medication?\",\n",
        "    \"When you feel better, do you sometimes stop taking your medication?\",\n",
        "    \"Sometimes if you feel worse when you take the medication, do you stop taking it?\",\n",
        "    \"I take my medication only when I am sick\"\n",
        "]\n",
        "df[\"adherence\"] = np.where(df[non_adherence_columns].eq(\"Yes\").any(axis=1), 0, 1)\n",
        "\n",
        "# Drop redundant columns\n",
        "df = df.drop(columns=non_adherence_columns + [\"If you have any further comments about medication or this questionnaire, please write them below\"])\n",
        "\n",
        "# Encode categorical features\n",
        "categorical_cols = df.select_dtypes(include=['object', 'category']).columns\n",
        "for col in categorical_cols:\n",
        "    le = LabelEncoder()\n",
        "    df[col] = le.fit_transform(df[col].astype(str))\n",
        "\n",
        "# Split features and labels\n",
        "X = df.drop(columns=\"adherence\").values\n",
        "y = df[\"adherence\"].values\n",
        "\n",
        "# Split into train, validation, and test sets\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, stratify=y_temp, random_state=42)\n",
        "\n",
        "# Apply SMOTE to the training data to balance the classes\n",
        "smote = SMOTE(sampling_strategy='auto', random_state=42)\n",
        "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "# Normalize features\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train_resampled)\n",
        "X_val = scaler.transform(X_val)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Convert to PyTorch tensors\n",
        "train_dataset = TensorDataset(torch.FloatTensor(X_train), torch.FloatTensor(y_train_resampled))\n",
        "val_dataset = TensorDataset(torch.FloatTensor(X_val), torch.FloatTensor(y_val))\n",
        "test_dataset = TensorDataset(torch.FloatTensor(X_test), torch.FloatTensor(y_test))\n",
        "\n",
        "# Create DataLoader\n",
        "batch_size = 32\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size)\n"
      ],
      "metadata": {
        "id": "6ByhGVVvJhOe"
      },
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " Define Teacher Model"
      ],
      "metadata": {
        "id": "aclSCnQBJnC9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class TeacherModel(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super(TeacherModel, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, 128)\n",
        "        self.fc2 = nn.Linear(128, 64)\n",
        "        self.fc3 = nn.Linear(64, 1)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        x = self.sigmoid(x)\n",
        "        return x\n",
        "\n",
        "# Initialize teacher model\n",
        "teacher_model = TeacherModel(input_dim=X_train.shape[1])\n",
        "teacher_model.to(device)  # Move to GPU if available\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BDVTTOtyJuMt",
        "outputId": "b4d18fcf-d9d3-4f53-b1e6-6debce9e5ac7"
      },
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TeacherModel(\n",
              "  (fc1): Linear(in_features=59, out_features=128, bias=True)\n",
              "  (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
              "  (fc3): Linear(in_features=64, out_features=1, bias=True)\n",
              "  (sigmoid): Sigmoid()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train the Teacher Model"
      ],
      "metadata": {
        "id": "KzcyJuh4J6NS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.Adam(teacher_model.parameters(), lr=0.001)\n",
        "\n",
        "epochs = 10\n",
        "for epoch in range(epochs):\n",
        "    teacher_model.train()\n",
        "    total_loss = 0.0\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = teacher_model(inputs).squeeze()\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {total_loss:.4f}\")\n",
        "\n",
        "# Save the trained teacher model\n",
        "torch.save(teacher_model.state_dict(), \"best_teacher.pth\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A7YCd9oNJ_S1",
        "outputId": "12bd8392-a953-4ffe-90dd-14b5373446bd"
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Loss: 2.8178\n",
            "Epoch 2/10, Loss: 2.6501\n",
            "Epoch 3/10, Loss: 2.5464\n",
            "Epoch 4/10, Loss: 2.3624\n",
            "Epoch 5/10, Loss: 2.2547\n",
            "Epoch 6/10, Loss: 2.1743\n",
            "Epoch 7/10, Loss: 2.0328\n",
            "Epoch 8/10, Loss: 1.8023\n",
            "Epoch 9/10, Loss: 1.5875\n",
            "Epoch 10/10, Loss: 1.4401\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluate the Teacher Model"
      ],
      "metadata": {
        "id": "VkeLplHTKgNv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score\n",
        "\n",
        "# Evaluate the Teacher Model on the validation set\n",
        "teacher_model.eval()\n",
        "val_preds, val_true = [], []\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in val_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        outputs = teacher_model(inputs).squeeze()\n",
        "        val_preds.extend(outputs.cpu().numpy())\n",
        "        val_true.extend(labels.cpu().numpy())\n",
        "\n",
        "# Convert predictions to binary (0 or 1)\n",
        "val_preds_binary = (np.array(val_preds) > 0.5).astype(int)\n",
        "\n",
        "# Calculate metrics\n",
        "val_precision = precision_score(val_true, val_preds_binary)\n",
        "val_recall = recall_score(val_true, val_preds_binary)\n",
        "val_f1 = f1_score(val_true, val_preds_binary)\n",
        "val_auc = roc_auc_score(val_true, val_preds)\n",
        "\n",
        "print(\"Teacher Model Evaluation (Validation Set):\")\n",
        "print(f\"Val Precision: {val_precision:.4f} | Val Recall: {val_recall:.4f}\")\n",
        "print(f\"Val F1-Score: {val_f1:.4f} | Val AUC: {val_auc:.4f}\")\n",
        "\n",
        "# Evaluate the Teacher Model on the test set\n",
        "test_preds, test_true = [], []\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in test_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        outputs = teacher_model(inputs).squeeze()\n",
        "        test_preds.extend(outputs.cpu().numpy())\n",
        "        test_true.extend(labels.cpu().numpy())\n",
        "\n",
        "# Convert predictions to binary (0 or 1)\n",
        "test_preds_binary = (np.array(test_preds) > 0.5).astype(int)\n",
        "\n",
        "# Calculate metrics\n",
        "test_precision = precision_score(test_true, test_preds_binary)\n",
        "test_recall = recall_score(test_true, test_preds_binary)\n",
        "test_f1 = f1_score(test_true, test_preds_binary)\n",
        "test_auc = roc_auc_score(test_true, test_preds)\n",
        "\n",
        "print(\"Teacher Model Evaluation (Test Set):\")\n",
        "print(f\"Test Precision: {test_precision:.4f} | Test Recall: {test_recall:.4f}\")\n",
        "print(f\"Test F1-Score: {test_f1:.4f} | Test AUC: {test_auc:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gkYt6WC0Khdk",
        "outputId": "353ef9b4-2643-4821-f495-6c4870eef5db"
      },
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Teacher Model Evaluation (Validation Set):\n",
            "Val Precision: 0.3333 | Val Recall: 0.1667\n",
            "Val F1-Score: 0.2222 | Val AUC: 0.7361\n",
            "Teacher Model Evaluation (Test Set):\n",
            "Test Precision: 0.2500 | Test Recall: 0.1667\n",
            "Test F1-Score: 0.2000 | Test AUC: 0.5000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load Teacher Model and Define Student Model"
      ],
      "metadata": {
        "id": "nGs_98nZKmD8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the trained teacher model\n",
        "teacher_model = TeacherModel(input_dim=X_train.shape[1])\n",
        "teacher_model.load_state_dict(torch.load(\"best_teacher.pth\"))\n",
        "teacher_model.eval()  # Set to evaluation mode\n",
        "teacher_model.to(device)\n",
        "\n",
        "# Define the Student Model\n",
        "class StudentModel(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super(StudentModel, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, 64)\n",
        "        self.fc2 = nn.Linear(64, 32)\n",
        "        self.fc3 = nn.Linear(32, 1)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        x = self.sigmoid(x)\n",
        "        return x\n",
        "\n",
        "# Initialize student model\n",
        "student_model = StudentModel(input_dim=X_train.shape[1])\n",
        "student_model.to(device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "buxZilgtK5wj",
        "outputId": "d92dd5a4-8035-4d44-ae1a-6b10f541cc5c"
      },
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-122-202fad7a504f>:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  teacher_model.load_state_dict(torch.load(\"best_teacher.pth\"))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "StudentModel(\n",
              "  (fc1): Linear(in_features=59, out_features=64, bias=True)\n",
              "  (fc2): Linear(in_features=64, out_features=32, bias=True)\n",
              "  (fc3): Linear(in_features=32, out_features=1, bias=True)\n",
              "  (sigmoid): Sigmoid()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Distillation Loss Function"
      ],
      "metadata": {
        "id": "-GMNXjhuLFpe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "def distillation_loss(student_preds, teacher_preds, labels, alpha=0.7, temperature=2.0):\n",
        "    # BCE loss for the student's binary classification task\n",
        "    loss_bce = nn.BCELoss()(student_preds.squeeze(), labels)  # Ensure predictions are squeezed to match label shape\n",
        "\n",
        "    # Teacher's predictions should be detached for distillation loss\n",
        "    teacher_preds = teacher_preds.detach()\n",
        "\n",
        "    # Distillation loss (KL Divergence between the student and teacher predictions)\n",
        "    distillation_loss = nn.KLDivLoss(reduction='batchmean')(\n",
        "        F.log_softmax(student_preds / temperature, dim=0),\n",
        "        F.softmax(teacher_preds / temperature, dim=0)\n",
        "    )\n",
        "\n",
        "    # Combined loss\n",
        "    total_loss = alpha * loss_bce + (1 - alpha) * distillation_loss\n",
        "    return total_loss\n"
      ],
      "metadata": {
        "id": "zSOX0DESLLO4"
      },
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train the Student Model with Distillation"
      ],
      "metadata": {
        "id": "YpapJc7BLPv2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the best saved teacher model\n",
        "teacher_model.load_state_dict(torch.load(\"best_teacher.pth\"))\n",
        "teacher_model.eval()  # Set teacher model to evaluation mode\n",
        "\n",
        "# Training loop for student model\n",
        "best_val_loss = float(\"inf\")\n",
        "for epoch in range(epochs):\n",
        "    student_model.train()\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        # Forward pass for teacher and student models\n",
        "        teacher_preds = teacher_model(inputs)\n",
        "        student_preds = student_model(inputs)\n",
        "\n",
        "        # Calculate distillation loss\n",
        "        loss = distillation_loss(student_preds.squeeze(), teacher_preds.squeeze(), labels)\n",
        "\n",
        "        # Zero gradients, backward pass and optimize\n",
        "        optimizer_student.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer_student.step()\n",
        "\n",
        "    # Validation loop\n",
        "    student_model.eval()\n",
        "    val_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in val_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            student_preds = student_model(inputs)\n",
        "            teacher_preds = teacher_model(inputs)\n",
        "            loss = distillation_loss(student_preds.squeeze(), teacher_preds.squeeze(), labels)\n",
        "            val_loss += loss.item()\n",
        "\n",
        "    val_loss /= len(val_loader)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{epochs}, Student Validation Loss: {val_loss:.4f}\")\n",
        "\n",
        "    # Early stopping based on validation loss\n",
        "    if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss\n",
        "        torch.save(student_model.state_dict(), \"best_student.pth\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jbjLmEfsLT-V",
        "outputId": "67617996-6971-4713-f530-5a2c769ed0ae"
      },
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Student Validation Loss: 0.5382\n",
            "Epoch 2/10, Student Validation Loss: 0.5382\n",
            "Epoch 3/10, Student Validation Loss: 0.5382\n",
            "Epoch 4/10, Student Validation Loss: 0.5382\n",
            "Epoch 5/10, Student Validation Loss: 0.5382\n",
            "Epoch 6/10, Student Validation Loss: 0.5382\n",
            "Epoch 7/10, Student Validation Loss: 0.5382\n",
            "Epoch 8/10, Student Validation Loss: 0.5382\n",
            "Epoch 9/10, Student Validation Loss: 0.5382\n",
            "Epoch 10/10, Student Validation Loss: 0.5382\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-131-1a506f72513f>:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  teacher_model.load_state_dict(torch.load(\"best_teacher.pth\"))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "evaluate student moel"
      ],
      "metadata": {
        "id": "lQjoX2OZNhxv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the best student model for evaluation\n",
        "student_model.load_state_dict(torch.load(\"best_student.pth\"))\n",
        "student_model.eval()\n",
        "\n",
        "# Initialize metrics for student model\n",
        "test_preds_student, test_true = [], []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in test_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        outputs_student = student_model(inputs).squeeze()\n",
        "        test_preds_student.extend(outputs_student.cpu().numpy())\n",
        "        test_true.extend(labels.cpu().numpy())\n",
        "\n",
        "# Convert predictions to binary (0 or 1)\n",
        "test_preds_student_binary = (np.array(test_preds_student) > 0.3).astype(int)\n",
        "\n",
        "# Calculate metrics for student model\n",
        "test_precision_student = precision_score(test_true, test_preds_student_binary)\n",
        "test_recall_student = recall_score(test_true, test_preds_student_binary)\n",
        "test_f1_student = f1_score(test_true, test_preds_student_binary)\n",
        "test_auc_student = roc_auc_score(test_true, test_preds_student)\n",
        "\n",
        "print(f\"Student Model Test Metrics:\")\n",
        "print(f\"Test Precision: {test_precision_student:.4f} | Test Recall: {test_recall_student:.4f}\")\n",
        "print(f\"Test F1-Score: {test_f1_student:.4f} | Test AUC: {test_auc_student:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AT7FJtIpNlQl",
        "outputId": "82731427-1f48-4f9c-a073-15e5f43ffb5e"
      },
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Student Model Test Metrics:\n",
            "Test Precision: 0.3333 | Test Recall: 1.0000\n",
            "Test F1-Score: 0.5000 | Test AUC: 0.7083\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-136-e4c329839e03>:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  student_model.load_state_dict(torch.load(\"best_student.pth\"))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New section"
      ],
      "metadata": {
        "id": "8jo8AyjIWUam"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Implement the Feedforward Neural Network"
      ],
      "metadata": {
        "id": "ZBQGUIJkWZSt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1 Implementation"
      ],
      "metadata": {
        "id": "ysSZziXGX0ND"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# Define the first model architecture (Feedforward Neural Network)\n",
        "class FeedForwardNN(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super(FeedForwardNN, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, 64)  # First hidden layer\n",
        "        self.fc2 = nn.Linear(64, 32)         # Second hidden layer\n",
        "        self.fc3 = nn.Linear(32, 1)          # Output layer\n",
        "        self.sigmoid = nn.Sigmoid()          # Sigmoid activation for binary classification\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.fc1(x))           # ReLU activation\n",
        "        x = torch.relu(self.fc2(x))           # ReLU activation\n",
        "        x = self.sigmoid(self.fc3(x))         # Output layer with sigmoid activation\n",
        "        return x\n",
        "\n",
        "# Example input dimension (you should use the actual number of features)\n",
        "input_dim = X_train.shape[1]  # assuming X_train is already defined\n",
        "model = FeedForwardNN(input_dim)\n",
        "\n",
        "# Define optimizer and loss function\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "loss_fn = nn.BCELoss()  # Binary Cross Entropy for binary classification\n",
        "\n",
        "# Training loop\n",
        "def train_model(model, train_loader, val_loader, optimizer, loss_fn, epochs=100):\n",
        "    best_val_loss = float('inf')\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        train_loss = 0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(inputs)\n",
        "            loss = loss_fn(outputs.squeeze(), labels)  # Squeeze to make outputs the same shape as labels\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss += loss.item()\n",
        "\n",
        "            # Calculate accuracy\n",
        "            predicted = (outputs > 0.5).float()\n",
        "            correct += (predicted.squeeze() == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "\n",
        "        # Validation step\n",
        "        model.eval()\n",
        "        val_loss = 0\n",
        "        val_correct = 0\n",
        "        val_total = 0\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in val_loader:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "                outputs = model(inputs)\n",
        "                val_loss += loss_fn(outputs.squeeze(), labels).item()\n",
        "\n",
        "                predicted = (outputs > 0.5).float()\n",
        "                val_correct += (predicted.squeeze() == labels).sum().item()\n",
        "                val_total += labels.size(0)\n",
        "\n",
        "        # Calculate metrics\n",
        "        train_loss = train_loss / len(train_loader)\n",
        "        train_accuracy = correct / total\n",
        "        val_loss = val_loss / len(val_loader)\n",
        "        val_accuracy = val_correct / val_total\n",
        "\n",
        "        print(f\"Epoch {epoch + 1}/{epochs}, Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}, \"\n",
        "              f\"Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}\")\n",
        "\n",
        "        # Save model if it's the best validation loss\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            torch.save(model.state_dict(), \"best_feedforward_model.pth\")\n",
        "\n",
        "# Move the model to the device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "# Train the model\n",
        "train_model(model, train_loader, val_loader, optimizer, loss_fn)\n"
      ],
      "metadata": {
        "id": "P5w4eM-WXXR5",
        "outputId": "95a26aa6-2bdd-40eb-c7e9-30f095a8002d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100, Train Loss: 0.7077, Train Accuracy: 0.5000, Val Loss: 0.7428, Val Accuracy: 0.3333\n",
            "Epoch 2/100, Train Loss: 0.6827, Train Accuracy: 0.5182, Val Loss: 0.7225, Val Accuracy: 0.5000\n",
            "Epoch 3/100, Train Loss: 0.6629, Train Accuracy: 0.5818, Val Loss: 0.7050, Val Accuracy: 0.5000\n",
            "Epoch 4/100, Train Loss: 0.6504, Train Accuracy: 0.6727, Val Loss: 0.6895, Val Accuracy: 0.6111\n",
            "Epoch 5/100, Train Loss: 0.6287, Train Accuracy: 0.7727, Val Loss: 0.6730, Val Accuracy: 0.6667\n",
            "Epoch 6/100, Train Loss: 0.6105, Train Accuracy: 0.8000, Val Loss: 0.6559, Val Accuracy: 0.6111\n",
            "Epoch 7/100, Train Loss: 0.5879, Train Accuracy: 0.8364, Val Loss: 0.6373, Val Accuracy: 0.5556\n",
            "Epoch 8/100, Train Loss: 0.5620, Train Accuracy: 0.8455, Val Loss: 0.6194, Val Accuracy: 0.5000\n",
            "Epoch 9/100, Train Loss: 0.5321, Train Accuracy: 0.8727, Val Loss: 0.6034, Val Accuracy: 0.5000\n",
            "Epoch 10/100, Train Loss: 0.5039, Train Accuracy: 0.8909, Val Loss: 0.5878, Val Accuracy: 0.5000\n",
            "Epoch 11/100, Train Loss: 0.4685, Train Accuracy: 0.8909, Val Loss: 0.5746, Val Accuracy: 0.5556\n",
            "Epoch 12/100, Train Loss: 0.4354, Train Accuracy: 0.9091, Val Loss: 0.5639, Val Accuracy: 0.5556\n",
            "Epoch 13/100, Train Loss: 0.3930, Train Accuracy: 0.9091, Val Loss: 0.5572, Val Accuracy: 0.5556\n",
            "Epoch 14/100, Train Loss: 0.3705, Train Accuracy: 0.9182, Val Loss: 0.5546, Val Accuracy: 0.6111\n",
            "Epoch 15/100, Train Loss: 0.3543, Train Accuracy: 0.9182, Val Loss: 0.5560, Val Accuracy: 0.6111\n",
            "Epoch 16/100, Train Loss: 0.3040, Train Accuracy: 0.9364, Val Loss: 0.5587, Val Accuracy: 0.6667\n",
            "Epoch 17/100, Train Loss: 0.2613, Train Accuracy: 0.9636, Val Loss: 0.5592, Val Accuracy: 0.7778\n",
            "Epoch 18/100, Train Loss: 0.2371, Train Accuracy: 0.9727, Val Loss: 0.5627, Val Accuracy: 0.7778\n",
            "Epoch 19/100, Train Loss: 0.2097, Train Accuracy: 0.9818, Val Loss: 0.5690, Val Accuracy: 0.7778\n",
            "Epoch 20/100, Train Loss: 0.1778, Train Accuracy: 0.9818, Val Loss: 0.5741, Val Accuracy: 0.7778\n",
            "Epoch 21/100, Train Loss: 0.1543, Train Accuracy: 0.9818, Val Loss: 0.5794, Val Accuracy: 0.7222\n",
            "Epoch 22/100, Train Loss: 0.1389, Train Accuracy: 0.9818, Val Loss: 0.5872, Val Accuracy: 0.7222\n",
            "Epoch 23/100, Train Loss: 0.1140, Train Accuracy: 0.9818, Val Loss: 0.5946, Val Accuracy: 0.7222\n",
            "Epoch 24/100, Train Loss: 0.0965, Train Accuracy: 0.9818, Val Loss: 0.6016, Val Accuracy: 0.7222\n",
            "Epoch 25/100, Train Loss: 0.0815, Train Accuracy: 0.9818, Val Loss: 0.6077, Val Accuracy: 0.7222\n",
            "Epoch 26/100, Train Loss: 0.0769, Train Accuracy: 0.9909, Val Loss: 0.6118, Val Accuracy: 0.7222\n",
            "Epoch 27/100, Train Loss: 0.0620, Train Accuracy: 0.9909, Val Loss: 0.6164, Val Accuracy: 0.7222\n",
            "Epoch 28/100, Train Loss: 0.0516, Train Accuracy: 0.9909, Val Loss: 0.6245, Val Accuracy: 0.7222\n",
            "Epoch 29/100, Train Loss: 0.0459, Train Accuracy: 0.9909, Val Loss: 0.6316, Val Accuracy: 0.7222\n",
            "Epoch 30/100, Train Loss: 0.0383, Train Accuracy: 1.0000, Val Loss: 0.6395, Val Accuracy: 0.7222\n",
            "Epoch 31/100, Train Loss: 0.0316, Train Accuracy: 1.0000, Val Loss: 0.6484, Val Accuracy: 0.7222\n",
            "Epoch 32/100, Train Loss: 0.0271, Train Accuracy: 1.0000, Val Loss: 0.6580, Val Accuracy: 0.7222\n",
            "Epoch 33/100, Train Loss: 0.0246, Train Accuracy: 1.0000, Val Loss: 0.6690, Val Accuracy: 0.7222\n",
            "Epoch 34/100, Train Loss: 0.0212, Train Accuracy: 1.0000, Val Loss: 0.6773, Val Accuracy: 0.7222\n",
            "Epoch 35/100, Train Loss: 0.0184, Train Accuracy: 1.0000, Val Loss: 0.6865, Val Accuracy: 0.7222\n",
            "Epoch 36/100, Train Loss: 0.0176, Train Accuracy: 1.0000, Val Loss: 0.6949, Val Accuracy: 0.7222\n",
            "Epoch 37/100, Train Loss: 0.0149, Train Accuracy: 1.0000, Val Loss: 0.7021, Val Accuracy: 0.7222\n",
            "Epoch 38/100, Train Loss: 0.0123, Train Accuracy: 1.0000, Val Loss: 0.7100, Val Accuracy: 0.7222\n",
            "Epoch 39/100, Train Loss: 0.0116, Train Accuracy: 1.0000, Val Loss: 0.7176, Val Accuracy: 0.7222\n",
            "Epoch 40/100, Train Loss: 0.0115, Train Accuracy: 1.0000, Val Loss: 0.7252, Val Accuracy: 0.7222\n",
            "Epoch 41/100, Train Loss: 0.0094, Train Accuracy: 1.0000, Val Loss: 0.7320, Val Accuracy: 0.7222\n",
            "Epoch 42/100, Train Loss: 0.0084, Train Accuracy: 1.0000, Val Loss: 0.7391, Val Accuracy: 0.7222\n",
            "Epoch 43/100, Train Loss: 0.0079, Train Accuracy: 1.0000, Val Loss: 0.7460, Val Accuracy: 0.7222\n",
            "Epoch 44/100, Train Loss: 0.0076, Train Accuracy: 1.0000, Val Loss: 0.7530, Val Accuracy: 0.7222\n",
            "Epoch 45/100, Train Loss: 0.0070, Train Accuracy: 1.0000, Val Loss: 0.7595, Val Accuracy: 0.7222\n",
            "Epoch 46/100, Train Loss: 0.0066, Train Accuracy: 1.0000, Val Loss: 0.7661, Val Accuracy: 0.7222\n",
            "Epoch 47/100, Train Loss: 0.0060, Train Accuracy: 1.0000, Val Loss: 0.7723, Val Accuracy: 0.7222\n",
            "Epoch 48/100, Train Loss: 0.0060, Train Accuracy: 1.0000, Val Loss: 0.7783, Val Accuracy: 0.7222\n",
            "Epoch 49/100, Train Loss: 0.0052, Train Accuracy: 1.0000, Val Loss: 0.7843, Val Accuracy: 0.7222\n",
            "Epoch 50/100, Train Loss: 0.0052, Train Accuracy: 1.0000, Val Loss: 0.7903, Val Accuracy: 0.7222\n",
            "Epoch 51/100, Train Loss: 0.0047, Train Accuracy: 1.0000, Val Loss: 0.7956, Val Accuracy: 0.7222\n",
            "Epoch 52/100, Train Loss: 0.0047, Train Accuracy: 1.0000, Val Loss: 0.8009, Val Accuracy: 0.7222\n",
            "Epoch 53/100, Train Loss: 0.0045, Train Accuracy: 1.0000, Val Loss: 0.8059, Val Accuracy: 0.7222\n",
            "Epoch 54/100, Train Loss: 0.0041, Train Accuracy: 1.0000, Val Loss: 0.8108, Val Accuracy: 0.7222\n",
            "Epoch 55/100, Train Loss: 0.0038, Train Accuracy: 1.0000, Val Loss: 0.8160, Val Accuracy: 0.7222\n",
            "Epoch 56/100, Train Loss: 0.0037, Train Accuracy: 1.0000, Val Loss: 0.8209, Val Accuracy: 0.7222\n",
            "Epoch 57/100, Train Loss: 0.0033, Train Accuracy: 1.0000, Val Loss: 0.8260, Val Accuracy: 0.7222\n",
            "Epoch 58/100, Train Loss: 0.0034, Train Accuracy: 1.0000, Val Loss: 0.8310, Val Accuracy: 0.7222\n",
            "Epoch 59/100, Train Loss: 0.0031, Train Accuracy: 1.0000, Val Loss: 0.8360, Val Accuracy: 0.7222\n",
            "Epoch 60/100, Train Loss: 0.0030, Train Accuracy: 1.0000, Val Loss: 0.8403, Val Accuracy: 0.7222\n",
            "Epoch 61/100, Train Loss: 0.0030, Train Accuracy: 1.0000, Val Loss: 0.8446, Val Accuracy: 0.7222\n",
            "Epoch 62/100, Train Loss: 0.0027, Train Accuracy: 1.0000, Val Loss: 0.8487, Val Accuracy: 0.7222\n",
            "Epoch 63/100, Train Loss: 0.0027, Train Accuracy: 1.0000, Val Loss: 0.8529, Val Accuracy: 0.7222\n",
            "Epoch 64/100, Train Loss: 0.0028, Train Accuracy: 1.0000, Val Loss: 0.8569, Val Accuracy: 0.7222\n",
            "Epoch 65/100, Train Loss: 0.0024, Train Accuracy: 1.0000, Val Loss: 0.8605, Val Accuracy: 0.7222\n",
            "Epoch 66/100, Train Loss: 0.0025, Train Accuracy: 1.0000, Val Loss: 0.8643, Val Accuracy: 0.7222\n",
            "Epoch 67/100, Train Loss: 0.0022, Train Accuracy: 1.0000, Val Loss: 0.8683, Val Accuracy: 0.7222\n",
            "Epoch 68/100, Train Loss: 0.0022, Train Accuracy: 1.0000, Val Loss: 0.8721, Val Accuracy: 0.7222\n",
            "Epoch 69/100, Train Loss: 0.0022, Train Accuracy: 1.0000, Val Loss: 0.8762, Val Accuracy: 0.7222\n",
            "Epoch 70/100, Train Loss: 0.0020, Train Accuracy: 1.0000, Val Loss: 0.8798, Val Accuracy: 0.7222\n",
            "Epoch 71/100, Train Loss: 0.0020, Train Accuracy: 1.0000, Val Loss: 0.8833, Val Accuracy: 0.7222\n",
            "Epoch 72/100, Train Loss: 0.0019, Train Accuracy: 1.0000, Val Loss: 0.8866, Val Accuracy: 0.7222\n",
            "Epoch 73/100, Train Loss: 0.0019, Train Accuracy: 1.0000, Val Loss: 0.8905, Val Accuracy: 0.7222\n",
            "Epoch 74/100, Train Loss: 0.0017, Train Accuracy: 1.0000, Val Loss: 0.8947, Val Accuracy: 0.7222\n",
            "Epoch 75/100, Train Loss: 0.0017, Train Accuracy: 1.0000, Val Loss: 0.8985, Val Accuracy: 0.7222\n",
            "Epoch 76/100, Train Loss: 0.0016, Train Accuracy: 1.0000, Val Loss: 0.9021, Val Accuracy: 0.7222\n",
            "Epoch 77/100, Train Loss: 0.0015, Train Accuracy: 1.0000, Val Loss: 0.9055, Val Accuracy: 0.7222\n",
            "Epoch 78/100, Train Loss: 0.0016, Train Accuracy: 1.0000, Val Loss: 0.9090, Val Accuracy: 0.7222\n",
            "Epoch 79/100, Train Loss: 0.0015, Train Accuracy: 1.0000, Val Loss: 0.9124, Val Accuracy: 0.7222\n",
            "Epoch 80/100, Train Loss: 0.0015, Train Accuracy: 1.0000, Val Loss: 0.9156, Val Accuracy: 0.7222\n",
            "Epoch 81/100, Train Loss: 0.0015, Train Accuracy: 1.0000, Val Loss: 0.9188, Val Accuracy: 0.7222\n",
            "Epoch 82/100, Train Loss: 0.0013, Train Accuracy: 1.0000, Val Loss: 0.9216, Val Accuracy: 0.7222\n",
            "Epoch 83/100, Train Loss: 0.0013, Train Accuracy: 1.0000, Val Loss: 0.9247, Val Accuracy: 0.7222\n",
            "Epoch 84/100, Train Loss: 0.0015, Train Accuracy: 1.0000, Val Loss: 0.9276, Val Accuracy: 0.7222\n",
            "Epoch 85/100, Train Loss: 0.0013, Train Accuracy: 1.0000, Val Loss: 0.9301, Val Accuracy: 0.7222\n",
            "Epoch 86/100, Train Loss: 0.0012, Train Accuracy: 1.0000, Val Loss: 0.9331, Val Accuracy: 0.7222\n",
            "Epoch 87/100, Train Loss: 0.0012, Train Accuracy: 1.0000, Val Loss: 0.9360, Val Accuracy: 0.7222\n",
            "Epoch 88/100, Train Loss: 0.0011, Train Accuracy: 1.0000, Val Loss: 0.9387, Val Accuracy: 0.7778\n",
            "Epoch 89/100, Train Loss: 0.0011, Train Accuracy: 1.0000, Val Loss: 0.9415, Val Accuracy: 0.7778\n",
            "Epoch 90/100, Train Loss: 0.0012, Train Accuracy: 1.0000, Val Loss: 0.9443, Val Accuracy: 0.7778\n",
            "Epoch 91/100, Train Loss: 0.0011, Train Accuracy: 1.0000, Val Loss: 0.9470, Val Accuracy: 0.7778\n",
            "Epoch 92/100, Train Loss: 0.0011, Train Accuracy: 1.0000, Val Loss: 0.9497, Val Accuracy: 0.7778\n",
            "Epoch 93/100, Train Loss: 0.0010, Train Accuracy: 1.0000, Val Loss: 0.9523, Val Accuracy: 0.7778\n",
            "Epoch 94/100, Train Loss: 0.0010, Train Accuracy: 1.0000, Val Loss: 0.9549, Val Accuracy: 0.7778\n",
            "Epoch 95/100, Train Loss: 0.0010, Train Accuracy: 1.0000, Val Loss: 0.9573, Val Accuracy: 0.7778\n",
            "Epoch 96/100, Train Loss: 0.0010, Train Accuracy: 1.0000, Val Loss: 0.9600, Val Accuracy: 0.7778\n",
            "Epoch 97/100, Train Loss: 0.0011, Train Accuracy: 1.0000, Val Loss: 0.9625, Val Accuracy: 0.7778\n",
            "Epoch 98/100, Train Loss: 0.0009, Train Accuracy: 1.0000, Val Loss: 0.9650, Val Accuracy: 0.7778\n",
            "Epoch 99/100, Train Loss: 0.0009, Train Accuracy: 1.0000, Val Loss: 0.9674, Val Accuracy: 0.7778\n",
            "Epoch 100/100, Train Loss: 0.0009, Train Accuracy: 1.0000, Val Loss: 0.9700, Val Accuracy: 0.7778\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Prepare Data"
      ],
      "metadata": {
        "id": "x2CnxVsQYENi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Load data\n",
        "df = pd.read_csv(\"cleaned_mental_health_data.csv\")\n",
        "\n",
        "# Define adherence labels based on questionnaire responses\n",
        "non_adherence_columns = [\n",
        "    \"Do you ever forget to take your medication?\",\n",
        "    \"Are you careless at times about taking your medication?\",\n",
        "    \"When you feel better, do you sometimes stop taking your medication?\",\n",
        "    \"Sometimes if you feel worse when you take the medication, do you stop taking it?\",\n",
        "    \"I take my medication only when I am sick\"\n",
        "]\n",
        "\n",
        "df[\"adherence\"] = np.where(df[non_adherence_columns].eq(\"Yes\").any(axis=1), 0, 1)\n",
        "\n",
        "# Drop redundant columns\n",
        "df = df.drop(columns=non_adherence_columns + [\"If you have any further comments about medication or this questionnaire, please write them below\"])\n",
        "\n",
        "# Identify all categorical columns\n",
        "categorical_cols = df.select_dtypes(include=['object', 'category']).columns\n",
        "print(\"Categorical columns to encode:\", categorical_cols)\n",
        "\n",
        "# Encode all categorical features\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "for col in categorical_cols:\n",
        "    le = LabelEncoder()\n",
        "    df[col] = le.fit_transform(df[col].astype(str))\n",
        "\n",
        "# Split features and labels\n",
        "X = df.drop(columns=\"adherence\").values\n",
        "y = df[\"adherence\"].values\n",
        "\n",
        "# Split data into train, validation, test (70-15-15)\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, stratify=y_temp, random_state=42)\n",
        "\n",
        "# Apply SMOTE to only the training set\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# Apply SMOTE only to the training data\n",
        "smote = SMOTE(sampling_strategy='auto', random_state=42)\n",
        "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "# Check new class distribution\n",
        "from collections import Counter\n",
        "print(\"New class distribution:\", Counter(y_train_resampled))\n",
        "\n",
        "# Normalize numerical features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train_resampled)\n",
        "X_val_scaled = scaler.transform(X_val)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Check the shape of the data to ensure it matches\n",
        "print(\"Shape of X_train_scaled:\", X_train_scaled.shape)\n",
        "print(\"Shape of y_train_resampled:\", y_train_resampled.shape)\n",
        "\n",
        "# Ensure that X_train_scaled and y_train_resampled have the same number of samples\n",
        "assert X_train_scaled.shape[0] == y_train_resampled.shape[0], \"Mismatch in number of samples between X_train_scaled and y_train_resampled\"\n",
        "\n",
        "# Convert to torch tensors\n",
        "train_tensor = TensorDataset(torch.tensor(X_train_scaled, dtype=torch.float32),\n",
        "                              torch.tensor(y_train_resampled, dtype=torch.float32))\n",
        "val_tensor = TensorDataset(torch.tensor(X_val_scaled, dtype=torch.float32),\n",
        "                            torch.tensor(y_val, dtype=torch.float32))\n",
        "test_tensor = TensorDataset(torch.tensor(X_test_scaled, dtype=torch.float32),\n",
        "                             torch.tensor(y_test, dtype=torch.float32))\n",
        "\n",
        "# Create DataLoaders\n",
        "batch_size = 32\n",
        "train_loader = DataLoader(train_tensor, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_tensor, batch_size=batch_size)\n",
        "test_loader = DataLoader(test_tensor, batch_size=batch_size)\n"
      ],
      "metadata": {
        "id": "o4mfmtVAYKJC",
        "outputId": "618e59c2-b22f-488d-897a-6d99f2e3bb16",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Categorical columns to encode: Index(['sex', 'Religion', 'marital status', 'education status', 'residence',\n",
            "       'substance use', 'comorbidity',\n",
            "       'It is unnatural for my mind and body to be controlled by medication?',\n",
            "       'My thoughts are clearer on medication',\n",
            "       'By staying on medication, I can prevent getting sick',\n",
            "       'I feel weird, like a ‘zombie’ on medication',\n",
            "       'Medication makes me feel tired and sluggish',\n",
            "       'Some of your symptoms are made by your mind.', 'You are mentally well',\n",
            "       'You do not need medication', 'Your stay in the hospital is necessary',\n",
            "       'The doctor is right in prescribing medication for you.',\n",
            "       'You do not need to be seen by a doctor or psychiatrist',\n",
            "       'If someone said you have a nervous or mental illness, they would be right',\n",
            "       'None of the unusual things you are experiencing are due to an illness.',\n",
            "       '. Loss of energy or drive', 'Feeling unmotivated or numb',\n",
            "       'Daytime sedation or drowsiness', 'Sleeping too much',\n",
            "       'Muscles being too tense or stiff', 'Muscles trembling or shaking',\n",
            "       'Feeling restless or jittery',\n",
            "       'Need to move around and pace; inability to sit still',\n",
            "       'Trouble getting to sleep or staying asleep (insomnia)',\n",
            "       'Blurry vision', 'Dry mouth', 'Drooling',\n",
            "       'Memory and concentration problems', 'Constipation', 'Weight changes',\n",
            "       'Changes in sexual functioning', 'Menstrual or breast problem',\n",
            "       'I feel over burdened by the number of pills i swallow per day.',\n",
            "       'How often do yo take your drugs',\n",
            "       'How often do you find no medications in the hospital',\n",
            "       'I am satisfied with doctors explanation about mental illness and the need for treatment',\n",
            "       'Do you sometimes stop your medications because of religious or cultural beliefs'],\n",
            "      dtype='object')\n",
            "New class distribution: Counter({1: 55, 0: 55})\n",
            "Shape of X_train_scaled: (110, 59)\n",
            "Shape of y_train_resampled: (110,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3 Model initialisation"
      ],
      "metadata": {
        "id": "-HMidXW5Yrpx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the FeedForwardNN model\n",
        "input_dim = X_train.shape[1]  # number of features in your dataset\n",
        "model = FeedForwardNN(input_dim)\n",
        "\n",
        "# Set device to GPU if available, otherwise use CPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "# Define optimizer and loss function\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "loss_fn = nn.BCELoss()  # Binary Cross Entropy Loss for binary classification\n"
      ],
      "metadata": {
        "id": "xWcNQjEuYwBH"
      },
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4 TRaining the model"
      ],
      "metadata": {
        "id": "0jzHG3RWYyzY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training the model\n",
        "train_model(model, train_loader, val_loader, optimizer, loss_fn, epochs=100)\n"
      ],
      "metadata": {
        "id": "YA7eZnOuY_zf",
        "outputId": "2d690c08-5479-4439-b3a3-a1dc830bb504",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100, Train Loss: 0.6876, Train Accuracy: 0.5818, Val Loss: 0.6774, Val Accuracy: 0.5556\n",
            "Epoch 2/100, Train Loss: 0.6628, Train Accuracy: 0.7000, Val Loss: 0.6593, Val Accuracy: 0.5556\n",
            "Epoch 3/100, Train Loss: 0.6476, Train Accuracy: 0.7727, Val Loss: 0.6403, Val Accuracy: 0.5556\n",
            "Epoch 4/100, Train Loss: 0.6316, Train Accuracy: 0.7818, Val Loss: 0.6214, Val Accuracy: 0.6111\n",
            "Epoch 5/100, Train Loss: 0.6092, Train Accuracy: 0.8182, Val Loss: 0.6022, Val Accuracy: 0.6667\n",
            "Epoch 6/100, Train Loss: 0.5837, Train Accuracy: 0.8545, Val Loss: 0.5828, Val Accuracy: 0.6667\n",
            "Epoch 7/100, Train Loss: 0.5746, Train Accuracy: 0.8545, Val Loss: 0.5662, Val Accuracy: 0.6667\n",
            "Epoch 8/100, Train Loss: 0.5603, Train Accuracy: 0.8909, Val Loss: 0.5529, Val Accuracy: 0.6667\n",
            "Epoch 9/100, Train Loss: 0.5318, Train Accuracy: 0.8818, Val Loss: 0.5427, Val Accuracy: 0.6667\n",
            "Epoch 10/100, Train Loss: 0.5092, Train Accuracy: 0.9091, Val Loss: 0.5372, Val Accuracy: 0.6667\n",
            "Epoch 11/100, Train Loss: 0.4702, Train Accuracy: 0.9273, Val Loss: 0.5356, Val Accuracy: 0.6667\n",
            "Epoch 12/100, Train Loss: 0.4595, Train Accuracy: 0.9364, Val Loss: 0.5362, Val Accuracy: 0.6667\n",
            "Epoch 13/100, Train Loss: 0.4218, Train Accuracy: 0.9455, Val Loss: 0.5401, Val Accuracy: 0.7778\n",
            "Epoch 14/100, Train Loss: 0.4131, Train Accuracy: 0.9455, Val Loss: 0.5472, Val Accuracy: 0.7778\n",
            "Epoch 15/100, Train Loss: 0.3682, Train Accuracy: 0.9455, Val Loss: 0.5557, Val Accuracy: 0.7778\n",
            "Epoch 16/100, Train Loss: 0.3368, Train Accuracy: 0.9636, Val Loss: 0.5691, Val Accuracy: 0.7778\n",
            "Epoch 17/100, Train Loss: 0.3207, Train Accuracy: 0.9636, Val Loss: 0.5839, Val Accuracy: 0.7778\n",
            "Epoch 18/100, Train Loss: 0.2879, Train Accuracy: 0.9636, Val Loss: 0.5999, Val Accuracy: 0.7778\n",
            "Epoch 19/100, Train Loss: 0.2559, Train Accuracy: 0.9909, Val Loss: 0.6176, Val Accuracy: 0.7778\n",
            "Epoch 20/100, Train Loss: 0.2293, Train Accuracy: 0.9909, Val Loss: 0.6365, Val Accuracy: 0.7778\n",
            "Epoch 21/100, Train Loss: 0.1945, Train Accuracy: 0.9909, Val Loss: 0.6599, Val Accuracy: 0.8333\n",
            "Epoch 22/100, Train Loss: 0.1675, Train Accuracy: 0.9909, Val Loss: 0.6814, Val Accuracy: 0.7778\n",
            "Epoch 23/100, Train Loss: 0.1437, Train Accuracy: 0.9909, Val Loss: 0.7059, Val Accuracy: 0.7778\n",
            "Epoch 24/100, Train Loss: 0.1280, Train Accuracy: 0.9909, Val Loss: 0.7332, Val Accuracy: 0.8333\n",
            "Epoch 25/100, Train Loss: 0.1034, Train Accuracy: 0.9909, Val Loss: 0.7606, Val Accuracy: 0.8333\n",
            "Epoch 26/100, Train Loss: 0.0881, Train Accuracy: 1.0000, Val Loss: 0.7882, Val Accuracy: 0.8333\n",
            "Epoch 27/100, Train Loss: 0.0718, Train Accuracy: 1.0000, Val Loss: 0.8139, Val Accuracy: 0.8333\n",
            "Epoch 28/100, Train Loss: 0.0612, Train Accuracy: 1.0000, Val Loss: 0.8392, Val Accuracy: 0.8333\n",
            "Epoch 29/100, Train Loss: 0.0526, Train Accuracy: 1.0000, Val Loss: 0.8621, Val Accuracy: 0.8333\n",
            "Epoch 30/100, Train Loss: 0.0462, Train Accuracy: 1.0000, Val Loss: 0.8852, Val Accuracy: 0.8333\n",
            "Epoch 31/100, Train Loss: 0.0396, Train Accuracy: 1.0000, Val Loss: 0.9074, Val Accuracy: 0.8333\n",
            "Epoch 32/100, Train Loss: 0.0336, Train Accuracy: 1.0000, Val Loss: 0.9306, Val Accuracy: 0.8333\n",
            "Epoch 33/100, Train Loss: 0.0288, Train Accuracy: 1.0000, Val Loss: 0.9524, Val Accuracy: 0.8333\n",
            "Epoch 34/100, Train Loss: 0.0265, Train Accuracy: 1.0000, Val Loss: 0.9729, Val Accuracy: 0.8333\n",
            "Epoch 35/100, Train Loss: 0.0227, Train Accuracy: 1.0000, Val Loss: 0.9930, Val Accuracy: 0.8333\n",
            "Epoch 36/100, Train Loss: 0.0201, Train Accuracy: 1.0000, Val Loss: 1.0120, Val Accuracy: 0.8333\n",
            "Epoch 37/100, Train Loss: 0.0194, Train Accuracy: 1.0000, Val Loss: 1.0309, Val Accuracy: 0.8333\n",
            "Epoch 38/100, Train Loss: 0.0162, Train Accuracy: 1.0000, Val Loss: 1.0481, Val Accuracy: 0.8333\n",
            "Epoch 39/100, Train Loss: 0.0150, Train Accuracy: 1.0000, Val Loss: 1.0637, Val Accuracy: 0.8333\n",
            "Epoch 40/100, Train Loss: 0.0133, Train Accuracy: 1.0000, Val Loss: 1.0777, Val Accuracy: 0.8333\n",
            "Epoch 41/100, Train Loss: 0.0119, Train Accuracy: 1.0000, Val Loss: 1.0907, Val Accuracy: 0.8333\n",
            "Epoch 42/100, Train Loss: 0.0112, Train Accuracy: 1.0000, Val Loss: 1.1030, Val Accuracy: 0.8333\n",
            "Epoch 43/100, Train Loss: 0.0102, Train Accuracy: 1.0000, Val Loss: 1.1152, Val Accuracy: 0.8333\n",
            "Epoch 44/100, Train Loss: 0.0090, Train Accuracy: 1.0000, Val Loss: 1.1269, Val Accuracy: 0.8333\n",
            "Epoch 45/100, Train Loss: 0.0087, Train Accuracy: 1.0000, Val Loss: 1.1388, Val Accuracy: 0.8333\n",
            "Epoch 46/100, Train Loss: 0.0077, Train Accuracy: 1.0000, Val Loss: 1.1507, Val Accuracy: 0.8333\n",
            "Epoch 47/100, Train Loss: 0.0073, Train Accuracy: 1.0000, Val Loss: 1.1627, Val Accuracy: 0.8333\n",
            "Epoch 48/100, Train Loss: 0.0069, Train Accuracy: 1.0000, Val Loss: 1.1740, Val Accuracy: 0.8333\n",
            "Epoch 49/100, Train Loss: 0.0067, Train Accuracy: 1.0000, Val Loss: 1.1854, Val Accuracy: 0.8333\n",
            "Epoch 50/100, Train Loss: 0.0064, Train Accuracy: 1.0000, Val Loss: 1.1960, Val Accuracy: 0.8333\n",
            "Epoch 51/100, Train Loss: 0.0057, Train Accuracy: 1.0000, Val Loss: 1.2062, Val Accuracy: 0.8333\n",
            "Epoch 52/100, Train Loss: 0.0057, Train Accuracy: 1.0000, Val Loss: 1.2153, Val Accuracy: 0.8333\n",
            "Epoch 53/100, Train Loss: 0.0049, Train Accuracy: 1.0000, Val Loss: 1.2247, Val Accuracy: 0.8333\n",
            "Epoch 54/100, Train Loss: 0.0048, Train Accuracy: 1.0000, Val Loss: 1.2332, Val Accuracy: 0.8333\n",
            "Epoch 55/100, Train Loss: 0.0046, Train Accuracy: 1.0000, Val Loss: 1.2416, Val Accuracy: 0.8333\n",
            "Epoch 56/100, Train Loss: 0.0045, Train Accuracy: 1.0000, Val Loss: 1.2497, Val Accuracy: 0.8333\n",
            "Epoch 57/100, Train Loss: 0.0043, Train Accuracy: 1.0000, Val Loss: 1.2579, Val Accuracy: 0.8333\n",
            "Epoch 58/100, Train Loss: 0.0038, Train Accuracy: 1.0000, Val Loss: 1.2659, Val Accuracy: 0.8333\n",
            "Epoch 59/100, Train Loss: 0.0037, Train Accuracy: 1.0000, Val Loss: 1.2736, Val Accuracy: 0.8333\n",
            "Epoch 60/100, Train Loss: 0.0037, Train Accuracy: 1.0000, Val Loss: 1.2810, Val Accuracy: 0.8333\n",
            "Epoch 61/100, Train Loss: 0.0036, Train Accuracy: 1.0000, Val Loss: 1.2879, Val Accuracy: 0.8333\n",
            "Epoch 62/100, Train Loss: 0.0033, Train Accuracy: 1.0000, Val Loss: 1.2951, Val Accuracy: 0.8333\n",
            "Epoch 63/100, Train Loss: 0.0033, Train Accuracy: 1.0000, Val Loss: 1.3021, Val Accuracy: 0.8333\n",
            "Epoch 64/100, Train Loss: 0.0033, Train Accuracy: 1.0000, Val Loss: 1.3084, Val Accuracy: 0.8333\n",
            "Epoch 65/100, Train Loss: 0.0029, Train Accuracy: 1.0000, Val Loss: 1.3151, Val Accuracy: 0.8333\n",
            "Epoch 66/100, Train Loss: 0.0029, Train Accuracy: 1.0000, Val Loss: 1.3212, Val Accuracy: 0.8333\n",
            "Epoch 67/100, Train Loss: 0.0029, Train Accuracy: 1.0000, Val Loss: 1.3273, Val Accuracy: 0.8333\n",
            "Epoch 68/100, Train Loss: 0.0026, Train Accuracy: 1.0000, Val Loss: 1.3335, Val Accuracy: 0.8333\n",
            "Epoch 69/100, Train Loss: 0.0027, Train Accuracy: 1.0000, Val Loss: 1.3394, Val Accuracy: 0.8333\n",
            "Epoch 70/100, Train Loss: 0.0024, Train Accuracy: 1.0000, Val Loss: 1.3451, Val Accuracy: 0.8333\n",
            "Epoch 71/100, Train Loss: 0.0024, Train Accuracy: 1.0000, Val Loss: 1.3512, Val Accuracy: 0.8333\n",
            "Epoch 72/100, Train Loss: 0.0022, Train Accuracy: 1.0000, Val Loss: 1.3566, Val Accuracy: 0.8333\n",
            "Epoch 73/100, Train Loss: 0.0023, Train Accuracy: 1.0000, Val Loss: 1.3621, Val Accuracy: 0.8333\n",
            "Epoch 74/100, Train Loss: 0.0022, Train Accuracy: 1.0000, Val Loss: 1.3676, Val Accuracy: 0.8333\n",
            "Epoch 75/100, Train Loss: 0.0020, Train Accuracy: 1.0000, Val Loss: 1.3729, Val Accuracy: 0.8333\n",
            "Epoch 76/100, Train Loss: 0.0022, Train Accuracy: 1.0000, Val Loss: 1.3780, Val Accuracy: 0.8333\n",
            "Epoch 77/100, Train Loss: 0.0019, Train Accuracy: 1.0000, Val Loss: 1.3829, Val Accuracy: 0.8333\n",
            "Epoch 78/100, Train Loss: 0.0020, Train Accuracy: 1.0000, Val Loss: 1.3877, Val Accuracy: 0.8333\n",
            "Epoch 79/100, Train Loss: 0.0019, Train Accuracy: 1.0000, Val Loss: 1.3924, Val Accuracy: 0.8333\n",
            "Epoch 80/100, Train Loss: 0.0018, Train Accuracy: 1.0000, Val Loss: 1.3973, Val Accuracy: 0.8333\n",
            "Epoch 81/100, Train Loss: 0.0018, Train Accuracy: 1.0000, Val Loss: 1.4021, Val Accuracy: 0.8333\n",
            "Epoch 82/100, Train Loss: 0.0017, Train Accuracy: 1.0000, Val Loss: 1.4069, Val Accuracy: 0.8333\n",
            "Epoch 83/100, Train Loss: 0.0017, Train Accuracy: 1.0000, Val Loss: 1.4117, Val Accuracy: 0.8333\n",
            "Epoch 84/100, Train Loss: 0.0015, Train Accuracy: 1.0000, Val Loss: 1.4166, Val Accuracy: 0.8333\n",
            "Epoch 85/100, Train Loss: 0.0015, Train Accuracy: 1.0000, Val Loss: 1.4216, Val Accuracy: 0.8333\n",
            "Epoch 86/100, Train Loss: 0.0015, Train Accuracy: 1.0000, Val Loss: 1.4263, Val Accuracy: 0.8333\n",
            "Epoch 87/100, Train Loss: 0.0015, Train Accuracy: 1.0000, Val Loss: 1.4311, Val Accuracy: 0.8333\n",
            "Epoch 88/100, Train Loss: 0.0014, Train Accuracy: 1.0000, Val Loss: 1.4353, Val Accuracy: 0.8333\n",
            "Epoch 89/100, Train Loss: 0.0014, Train Accuracy: 1.0000, Val Loss: 1.4397, Val Accuracy: 0.8333\n",
            "Epoch 90/100, Train Loss: 0.0014, Train Accuracy: 1.0000, Val Loss: 1.4440, Val Accuracy: 0.8333\n",
            "Epoch 91/100, Train Loss: 0.0013, Train Accuracy: 1.0000, Val Loss: 1.4484, Val Accuracy: 0.8333\n",
            "Epoch 92/100, Train Loss: 0.0013, Train Accuracy: 1.0000, Val Loss: 1.4526, Val Accuracy: 0.8333\n",
            "Epoch 93/100, Train Loss: 0.0012, Train Accuracy: 1.0000, Val Loss: 1.4569, Val Accuracy: 0.8333\n",
            "Epoch 94/100, Train Loss: 0.0013, Train Accuracy: 1.0000, Val Loss: 1.4608, Val Accuracy: 0.8333\n",
            "Epoch 95/100, Train Loss: 0.0011, Train Accuracy: 1.0000, Val Loss: 1.4651, Val Accuracy: 0.8333\n",
            "Epoch 96/100, Train Loss: 0.0012, Train Accuracy: 1.0000, Val Loss: 1.4690, Val Accuracy: 0.8333\n",
            "Epoch 97/100, Train Loss: 0.0012, Train Accuracy: 1.0000, Val Loss: 1.4730, Val Accuracy: 0.8333\n",
            "Epoch 98/100, Train Loss: 0.0011, Train Accuracy: 1.0000, Val Loss: 1.4769, Val Accuracy: 0.8333\n",
            "Epoch 99/100, Train Loss: 0.0011, Train Accuracy: 1.0000, Val Loss: 1.4805, Val Accuracy: 0.8333\n",
            "Epoch 100/100, Train Loss: 0.0011, Train Accuracy: 1.0000, Val Loss: 1.4841, Val Accuracy: 0.8333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5 Evaluation"
      ],
      "metadata": {
        "id": "Nl-csvbpZD8O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score\n",
        "\n",
        "# Define your model (for example, using a simple neural network)\n",
        "class SimpleNN(torch.nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super(SimpleNN, self).__init__()\n",
        "        self.fc1 = torch.nn.Linear(input_dim, 64)\n",
        "        self.fc2 = torch.nn.Linear(64, 32)\n",
        "        self.fc3 = torch.nn.Linear(32, 1)\n",
        "        self.sigmoid = torch.nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        x = self.sigmoid(x)\n",
        "        return x\n",
        "\n",
        "# Initialize model, optimizer, and loss function\n",
        "input_dim = X_train_scaled.shape[1]\n",
        "model = SimpleNN(input_dim)\n",
        "learning_rate = 0.001\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "criterion = torch.nn.BCELoss()\n",
        "\n",
        "# Start tracking training time\n",
        "start_time = time.time()\n",
        "\n",
        "# Training loop\n",
        "epochs = 10\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for inputs, labels in train_loader:\n",
        "        # Move data to GPU if available\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        # Zero gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs.squeeze(), labels)\n",
        "\n",
        "        # Backward pass and optimization\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update metrics\n",
        "        running_loss += loss.item()\n",
        "        predicted = (outputs.squeeze() > 0.5).float()\n",
        "        correct += (predicted == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "    epoch_loss = running_loss / len(train_loader)\n",
        "    epoch_accuracy = 100 * correct / total\n",
        "\n",
        "    # Evaluation on validation set after each epoch\n",
        "    model.eval()\n",
        "    val_preds, val_labels = [], []\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in val_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            val_preds.append(outputs.squeeze().cpu().numpy())\n",
        "            val_labels.append(labels.cpu().numpy())\n",
        "\n",
        "    val_preds = np.concatenate(val_preds)\n",
        "    val_labels = np.concatenate(val_labels)\n",
        "\n",
        "    # Calculate metrics\n",
        "    val_precision = precision_score(val_labels, (val_preds > 0.5).astype(int))\n",
        "    val_recall = recall_score(val_labels, (val_preds > 0.5).astype(int))\n",
        "    val_f1 = f1_score(val_labels, (val_preds > 0.5).astype(int))\n",
        "    val_auc = roc_auc_score(val_labels, val_preds)\n",
        "\n",
        "    # Print metrics\n",
        "    print(f\"Epoch {epoch+1}/{epochs} | Loss: {epoch_loss:.4f} | Accuracy: {epoch_accuracy:.2f}%\")\n",
        "    print(f\"Validation Precision: {val_precision:.4f} | Validation Recall: {val_recall:.4f}\")\n",
        "    print(f\"Validation F1-Score: {val_f1:.4f} | Validation AUC: {val_auc:.4f}\")\n",
        "\n",
        "# End training time\n",
        "end_time = time.time()\n",
        "training_time = end_time - start_time\n",
        "\n",
        "# Final evaluation on test set\n",
        "model.eval()\n",
        "test_preds, test_labels = [], []\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in test_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        outputs = model(inputs)\n",
        "        test_preds.append(outputs.squeeze().cpu().numpy())\n",
        "        test_labels.append(labels.cpu().numpy())\n",
        "\n",
        "test_preds = np.concatenate(test_preds)\n",
        "test_labels = np.concatenate(test_labels)\n",
        "\n",
        "# Calculate final test metrics\n",
        "test_precision = precision_score(test_labels, (test_preds > 0.5).astype(int))\n",
        "test_recall = recall_score(test_labels, (test_preds > 0.5).astype(int))\n",
        "test_f1 = f1_score(test_labels, (test_preds > 0.5).astype(int))\n",
        "test_auc = roc_auc_score(test_labels, test_preds)\n",
        "\n",
        "# Print test metrics\n",
        "print(\"\\nTest Metrics:\")\n",
        "print(f\"Test Precision: {test_precision:.4f} | Test Recall: {test_recall:.4f}\")\n",
        "print(f\"Test F1-Score: {test_f1:.4f} | Test AUC: {test_auc:.4f}\")\n",
        "\n",
        "# Print learning rate and training time\n",
        "print(f\"\\nLearning Rate: {learning_rate}\")\n",
        "print(f\"Training Time: {training_time:.2f} seconds\")\n"
      ],
      "metadata": {
        "id": "l4VXdK-bZJJW",
        "outputId": "37630113-1b98-48cc-9347-982d3559fe8f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10 | Loss: 0.6937 | Accuracy: 49.09%\n",
            "Validation Precision: 0.3333 | Validation Recall: 1.0000\n",
            "Validation F1-Score: 0.5000 | Validation AUC: 0.5694\n",
            "Epoch 2/10 | Loss: 0.6743 | Accuracy: 60.91%\n",
            "Validation Precision: 0.4167 | Validation Recall: 0.8333\n",
            "Validation F1-Score: 0.5556 | Validation AUC: 0.6944\n",
            "Epoch 3/10 | Loss: 0.6608 | Accuracy: 72.73%\n",
            "Validation Precision: 0.5000 | Validation Recall: 0.8333\n",
            "Validation F1-Score: 0.6250 | Validation AUC: 0.7500\n",
            "Epoch 4/10 | Loss: 0.6394 | Accuracy: 75.45%\n",
            "Validation Precision: 0.6250 | Validation Recall: 0.8333\n",
            "Validation F1-Score: 0.7143 | Validation AUC: 0.6944\n",
            "Epoch 5/10 | Loss: 0.6275 | Accuracy: 79.09%\n",
            "Validation Precision: 0.4000 | Validation Recall: 0.3333\n",
            "Validation F1-Score: 0.3636 | Validation AUC: 0.6806\n",
            "Epoch 6/10 | Loss: 0.6048 | Accuracy: 81.82%\n",
            "Validation Precision: 0.4000 | Validation Recall: 0.3333\n",
            "Validation F1-Score: 0.3636 | Validation AUC: 0.6667\n",
            "Epoch 7/10 | Loss: 0.5870 | Accuracy: 82.73%\n",
            "Validation Precision: 0.4000 | Validation Recall: 0.3333\n",
            "Validation F1-Score: 0.3636 | Validation AUC: 0.6667\n",
            "Epoch 8/10 | Loss: 0.5636 | Accuracy: 84.55%\n",
            "Validation Precision: 0.2500 | Validation Recall: 0.1667\n",
            "Validation F1-Score: 0.2000 | Validation AUC: 0.6806\n",
            "Epoch 9/10 | Loss: 0.5481 | Accuracy: 87.27%\n",
            "Validation Precision: 0.2500 | Validation Recall: 0.1667\n",
            "Validation F1-Score: 0.2000 | Validation AUC: 0.6806\n",
            "Epoch 10/10 | Loss: 0.5184 | Accuracy: 89.09%\n",
            "Validation Precision: 0.2500 | Validation Recall: 0.1667\n",
            "Validation F1-Score: 0.2000 | Validation AUC: 0.6806\n",
            "\n",
            "Test Metrics:\n",
            "Test Precision: 0.3333 | Test Recall: 0.1667\n",
            "Test F1-Score: 0.2222 | Test AUC: 0.5000\n",
            "\n",
            "Learning Rate: 0.001\n",
            "Training Time: 0.52 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Saving best model"
      ],
      "metadata": {
        "id": "euqsffLGZVVK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the best model for inference\n",
        "best_model = FeedForwardNN(input_dim)\n",
        "best_model.load_state_dict(torch.load(\"best_feedforward_model.pth\"))\n",
        "best_model.to(device)\n"
      ],
      "metadata": {
        "id": "qvj6IrhQZXf7",
        "outputId": "ee7d0fb9-68fe-45d3-a8ef-f72f17022784",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-143-55df29be72a9>:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  best_model.load_state_dict(torch.load(\"best_feedforward_model.pth\"))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FeedForwardNN(\n",
              "  (fc1): Linear(in_features=59, out_features=64, bias=True)\n",
              "  (fc2): Linear(in_features=64, out_features=32, bias=True)\n",
              "  (fc3): Linear(in_features=32, out_features=1, bias=True)\n",
              "  (sigmoid): Sigmoid()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 143
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Implement Logisitic Regretion"
      ],
      "metadata": {
        "id": "KlciCDP2a9ge"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1 Import Libraries"
      ],
      "metadata": {
        "id": "UbYCxxEFcj16"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "import time\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Assuming data preprocessing has been done and the data is available in these variables\n",
        "# X_train, X_val, X_test, y_train, y_val, y_test\n",
        "# Scaling features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_val_scaled = scaler.transform(X_val)\n",
        "X_test_scaled = scaler.transform(X_test)\n"
      ],
      "metadata": {
        "id": "xV1CAogFbJLk"
      },
      "execution_count": 147,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Training"
      ],
      "metadata": {
        "id": "xN9ha_HTcv_1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the Logistic Regression model\n",
        "logreg_model = LogisticRegression(random_state=42, max_iter=1000)\n",
        "\n",
        "# Record the start time for training\n",
        "start_time = time.time()\n",
        "\n",
        "# Train the model\n",
        "logreg_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Record the end time for training\n",
        "end_time = time.time()\n",
        "\n",
        "# Calculate the training time\n",
        "training_time = end_time - start_time\n"
      ],
      "metadata": {
        "id": "oZZWnBw6c12n"
      },
      "execution_count": 148,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Evaluation"
      ],
      "metadata": {
        "id": "deejg0w_c3h_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict on train, validation, and test sets\n",
        "y_train_pred = logreg_model.predict(X_train_scaled)\n",
        "y_val_pred = logreg_model.predict(X_val_scaled)\n",
        "y_test_pred = logreg_model.predict(X_test_scaled)\n",
        "\n",
        "# Calculate metrics for training, validation, and test sets\n",
        "train_precision = precision_score(y_train, y_train_pred)\n",
        "train_recall = recall_score(y_train, y_train_pred)\n",
        "train_f1 = f1_score(y_train, y_train_pred)\n",
        "train_auc = roc_auc_score(y_train, y_train_pred)\n",
        "\n",
        "val_precision = precision_score(y_val, y_val_pred)\n",
        "val_recall = recall_score(y_val, y_val_pred)\n",
        "val_f1 = f1_score(y_val, y_val_pred)\n",
        "val_auc = roc_auc_score(y_val, y_val_pred)\n",
        "\n",
        "test_precision = precision_score(y_test, y_test_pred)\n",
        "test_recall = recall_score(y_test, y_test_pred)\n",
        "test_f1 = f1_score(y_test, y_test_pred)\n",
        "test_auc = roc_auc_score(y_test, y_test_pred)\n",
        "\n",
        "# Print the metrics and training time\n",
        "print(f\"Training time: {training_time:.2f} seconds\")\n",
        "print(f\"Training Precision: {train_precision:.4f} | Training Recall: {train_recall:.4f} | Training F1-Score: {train_f1:.4f} | Training AUC: {train_auc:.4f}\")\n",
        "print(f\"Validation Precision: {val_precision:.4f} | Validation Recall: {val_recall:.4f} | Validation F1-Score: {val_f1:.4f} | Validation AUC: {val_auc:.4f}\")\n",
        "print(f\"Test Precision: {test_precision:.4f} | Test Recall: {test_recall:.4f} | Test F1-Score: {test_f1:.4f} | Test AUC: {test_auc:.4f}\")\n"
      ],
      "metadata": {
        "id": "BR_Vi3aqc5mo",
        "outputId": "5a4675f8-7526-434e-ba60-a554caf0542d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training time: 0.07 seconds\n",
            "Training Precision: 1.0000 | Training Recall: 1.0000 | Training F1-Score: 1.0000 | Training AUC: 1.0000\n",
            "Validation Precision: 1.0000 | Validation Recall: 0.5000 | Validation F1-Score: 0.6667 | Validation AUC: 0.7500\n",
            "Test Precision: 0.2500 | Test Recall: 0.1667 | Test F1-Score: 0.2000 | Test AUC: 0.4583\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Implementing Support Vector Machine"
      ],
      "metadata": {
        "id": "RYj2KN_odCZE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "import time\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Assuming data preprocessing has been done and the data is available in these variables\n",
        "# X_train, X_val, X_test, y_train, y_val, y_test\n",
        "# Scaling features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_val_scaled = scaler.transform(X_val)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "\n",
        "# Initialize the SVM model with a radial basis function kernel\n",
        "svm_model = SVC(probability=True, random_state=42)\n",
        "\n",
        "# Record the start time for training\n",
        "start_time = time.time()\n",
        "\n",
        "# Train the model\n",
        "svm_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Record the end time for training\n",
        "end_time = time.time()\n",
        "\n",
        "# Calculate the training time\n",
        "training_time = end_time - start_time\n"
      ],
      "metadata": {
        "id": "rweuNg7udRko"
      },
      "execution_count": 150,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluation"
      ],
      "metadata": {
        "id": "Z9kyZ_mNde_I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict on train, validation, and test sets\n",
        "y_train_pred = svm_model.predict(X_train_scaled)\n",
        "y_val_pred = svm_model.predict(X_val_scaled)\n",
        "y_test_pred = svm_model.predict(X_test_scaled)\n",
        "\n",
        "# Calculate metrics for training, validation, and test sets\n",
        "train_precision = precision_score(y_train, y_train_pred)\n",
        "train_recall = recall_score(y_train, y_train_pred)\n",
        "train_f1 = f1_score(y_train, y_train_pred)\n",
        "train_auc = roc_auc_score(y_train, svm_model.predict_proba(X_train_scaled)[:, 1])\n",
        "\n",
        "val_precision = precision_score(y_val, y_val_pred)\n",
        "val_recall = recall_score(y_val, y_val_pred)\n",
        "val_f1 = f1_score(y_val, y_val_pred)\n",
        "val_auc = roc_auc_score(y_val, svm_model.predict_proba(X_val_scaled)[:, 1])\n",
        "\n",
        "test_precision = precision_score(y_test, y_test_pred)\n",
        "test_recall = recall_score(y_test, y_test_pred)\n",
        "test_f1 = f1_score(y_test, y_test_pred)\n",
        "test_auc = roc_auc_score(y_test, svm_model.predict_proba(X_test_scaled)[:, 1])\n",
        "\n",
        "# Print the metrics and training time\n",
        "print(f\"Training time: {training_time:.2f} seconds\")\n",
        "print(f\"Training Precision: {train_precision:.4f} | Training Recall: {train_recall:.4f} | Training F1-Score: {train_f1:.4f} | Training AUC: {train_auc:.4f}\")\n",
        "print(f\"Validation Precision: {val_precision:.4f} | Validation Recall: {val_recall:.4f} | Validation F1-Score: {val_f1:.4f} | Validation AUC: {val_auc:.4f}\")\n",
        "print(f\"Test Precision: {test_precision:.4f} | Test Recall: {test_recall:.4f} | Test F1-Score: {test_f1:.4f} | Test AUC: {test_auc:.4f}\")\n"
      ],
      "metadata": {
        "id": "l0y3VIgydgzl",
        "outputId": "b2a5f2e0-daa0-413e-ff6f-73ca51ba6efa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training time: 0.01 seconds\n",
            "Training Precision: 1.0000 | Training Recall: 0.7308 | Training F1-Score: 0.8444 | Training AUC: 1.0000\n",
            "Validation Precision: 1.0000 | Validation Recall: 0.1667 | Validation F1-Score: 0.2857 | Validation AUC: 0.6389\n",
            "Test Precision: 0.0000 | Test Recall: 0.0000 | Test F1-Score: 0.0000 | Test AUC: 0.4167\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Implementing Random Forest Classifier"
      ],
      "metadata": {
        "id": "Gxv7fW3_dqK8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import time\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Assuming data preprocessing has been done and the data is available in these variables\n",
        "# X_train, X_val, X_test, y_train, y_val, y_test\n",
        "# Scaling features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_val_scaled = scaler.transform(X_val)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "#TRAINING\n",
        "\n",
        "# Initialize the Random Forest model\n",
        "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# Record the start time for training\n",
        "start_time = time.time()\n",
        "\n",
        "# Train the model\n",
        "rf_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Record the end time for training\n",
        "end_time = time.time()\n",
        "\n",
        "# Calculate the training time\n",
        "training_time = end_time - start_time\n",
        "\n",
        "#EVALUATION\n",
        "\n",
        "# Predict on train, validation, and test sets\n",
        "y_train_pred = rf_model.predict(X_train_scaled)\n",
        "y_val_pred = rf_model.predict(X_val_scaled)\n",
        "y_test_pred = rf_model.predict(X_test_scaled)\n",
        "\n",
        "# Calculate metrics for training, validation, and test sets\n",
        "train_precision = precision_score(y_train, y_train_pred)\n",
        "train_recall = recall_score(y_train, y_train_pred)\n",
        "train_f1 = f1_score(y_train, y_train_pred)\n",
        "train_auc = roc_auc_score(y_train, rf_model.predict_proba(X_train_scaled)[:, 1])\n",
        "\n",
        "val_precision = precision_score(y_val, y_val_pred)\n",
        "val_recall = recall_score(y_val, y_val_pred)\n",
        "val_f1 = f1_score(y_val, y_val_pred)\n",
        "val_auc = roc_auc_score(y_val, rf_model.predict_proba(X_val_scaled)[:, 1])\n",
        "\n",
        "test_precision = precision_score(y_test, y_test_pred)\n",
        "test_recall = recall_score(y_test, y_test_pred)\n",
        "test_f1 = f1_score(y_test, y_test_pred)\n",
        "test_auc = roc_auc_score(y_test, rf_model.predict_proba(X_test_scaled)[:, 1])\n",
        "\n",
        "# Print the metrics and training time\n",
        "print(f\"Training time: {training_time:.2f} seconds\")\n",
        "print(f\"Training Precision: {train_precision:.4f} | Training Recall: {train_recall:.4f} | Training F1-Score: {train_f1:.4f} | Training AUC: {train_auc:.4f}\")\n",
        "print(f\"Validation Precision: {val_precision:.4f} | Validation Recall: {val_recall:.4f} | Validation F1-Score: {val_f1:.4f} | Validation AUC: {val_auc:.4f}\")\n",
        "print(f\"Test Precision: {test_precision:.4f} | Test Recall: {test_recall:.4f} | Test F1-Score: {test_f1:.4f} | Test AUC: {test_auc:.4f}\")\n"
      ],
      "metadata": {
        "id": "_6Sq7pKDd_kO",
        "outputId": "9d6c4da0-688d-441d-f991-482a751ab36d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training time: 0.15 seconds\n",
            "Training Precision: 1.0000 | Training Recall: 1.0000 | Training F1-Score: 1.0000 | Training AUC: 1.0000\n",
            "Validation Precision: 0.7500 | Validation Recall: 0.5000 | Validation F1-Score: 0.6000 | Validation AUC: 0.7917\n",
            "Test Precision: 1.0000 | Test Recall: 0.1667 | Test F1-Score: 0.2857 | Test AUC: 0.4653\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Implementing a K-Nearest Neighbor"
      ],
      "metadata": {
        "id": "VC7wLDMjfDAN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "import time\n",
        "\n",
        "# Initialize KNN model\n",
        "knn_model = KNeighborsClassifier(n_neighbors=5)\n",
        "\n",
        "# Record the start time for training\n",
        "start_time = time.time()\n",
        "\n",
        "# Train the model\n",
        "knn_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Record the end time for training\n",
        "end_time = time.time()\n",
        "\n",
        "# Calculate training time\n",
        "training_time = end_time - start_time\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred_knn = knn_model.predict(X_test_scaled)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred_knn)\n",
        "report = classification_report(y_test, y_pred_knn)\n",
        "\n",
        "# Store the metrics\n",
        "print(\"KNN Model Test Metrics:\")\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Training Time: {training_time:.4f} seconds\")\n",
        "print(\"Classification Report:\\n\", report)\n",
        "\n",
        "# Optionally, return metrics if you plan to store them\n",
        "metrics = {\n",
        "    \"model\": \"KNN\",\n",
        "    \"accuracy\": accuracy,\n",
        "    \"training_time\": training_time,\n",
        "    \"classification_report\": report\n",
        "}\n"
      ],
      "metadata": {
        "id": "89j6P0lBfPE2",
        "outputId": "c57d81a8-14cc-4dc2-eb93-5f0fb2048f12",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KNN Model Test Metrics:\n",
            "Accuracy: 0.7222\n",
            "Training Time: 0.0052 seconds\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.92      0.81        12\n",
            "           1       0.67      0.33      0.44         6\n",
            "\n",
            "    accuracy                           0.72        18\n",
            "   macro avg       0.70      0.62      0.63        18\n",
            "weighted avg       0.71      0.72      0.69        18\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implementing Gradient Boost machine"
      ],
      "metadata": {
        "id": "YEVJvZG7fUYp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score\n",
        "import time\n",
        "\n",
        "# Initialize Gradient Boosting Classifier\n",
        "gbm_model = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)\n",
        "\n",
        "# Record the start time for training\n",
        "start_time = time.time()\n",
        "\n",
        "# Train the model\n",
        "gbm_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Record the end time for training\n",
        "end_time = time.time()\n",
        "training_time = end_time - start_time\n",
        "\n",
        "# Predict on the validation and test sets\n",
        "y_val_pred = gbm_model.predict(X_val_scaled)\n",
        "y_test_pred = gbm_model.predict(X_test_scaled)\n",
        "\n",
        "# Calculate metrics for evaluation\n",
        "val_precision = precision_score(y_val, y_val_pred)\n",
        "val_recall = recall_score(y_val, y_val_pred)\n",
        "val_f1 = f1_score(y_val, y_val_pred)\n",
        "val_auc = roc_auc_score(y_val, gbm_model.predict_proba(X_val_scaled)[:, 1])\n",
        "\n",
        "test_precision = precision_score(y_test, y_test_pred)\n",
        "test_recall = recall_score(y_test, y_test_pred)\n",
        "test_f1 = f1_score(y_test, y_test_pred)\n",
        "test_auc = roc_auc_score(y_test, gbm_model.predict_proba(X_test_scaled)[:, 1])\n",
        "\n",
        "# Print the evaluation metrics\n",
        "print(f\"Gradient Boosting Model Evaluation (Validation Set):\")\n",
        "print(f\"Validation Precision: {val_precision:.4f} | Validation Recall: {val_recall:.4f}\")\n",
        "print(f\"Validation F1-Score: {val_f1:.4f} | Validation AUC: {val_auc:.4f}\")\n",
        "\n",
        "print(f\"\\nGradient Boosting Model Evaluation (Test Set):\")\n",
        "print(f\"Test Precision: {test_precision:.4f} | Test Recall: {test_recall:.4f}\")\n",
        "print(f\"Test F1-Score: {test_f1:.4f} | Test AUC: {test_auc:.4f}\")\n",
        "\n",
        "print(f\"\\nTraining Time: {training_time:.4f} seconds\")\n"
      ],
      "metadata": {
        "id": "wnfUNlupf0Vn",
        "outputId": "fa9aab3e-5853-495c-ed80-f9d1f4c64e59",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gradient Boosting Model Evaluation (Validation Set):\n",
            "Validation Precision: 0.5000 | Validation Recall: 0.5000\n",
            "Validation F1-Score: 0.5000 | Validation AUC: 0.6389\n",
            "\n",
            "Gradient Boosting Model Evaluation (Test Set):\n",
            "Test Precision: 0.3333 | Test Recall: 0.3333\n",
            "Test F1-Score: 0.3333 | Test AUC: 0.4444\n",
            "\n",
            "Training Time: 0.2934 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Implementing XGBoost"
      ],
      "metadata": {
        "id": "ODQ1xV3bf3dF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install xgboost\n"
      ],
      "metadata": {
        "id": "TlYAPJOsgTrO",
        "outputId": "b89e228f-dbd8-4708-83a8-f969dcac4f55",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.11/dist-packages (2.1.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from xgboost) (1.26.4)\n",
            "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.11/dist-packages (from xgboost) (2.21.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from xgboost) (1.13.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score\n",
        "import time\n",
        "\n",
        "# Initialize XGBoost Classifier\n",
        "xgboost_model = xgb.XGBClassifier(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)\n",
        "\n",
        "# Record the start time for training\n",
        "start_time = time.time()\n",
        "\n",
        "# Train the model\n",
        "xgboost_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Record the end time for training\n",
        "end_time = time.time()\n",
        "training_time = end_time - start_time\n",
        "\n",
        "# Predict on the validation and test sets\n",
        "y_val_pred = xgboost_model.predict(X_val_scaled)\n",
        "y_test_pred = xgboost_model.predict(X_test_scaled)\n",
        "\n",
        "# Calculate metrics for evaluation\n",
        "val_precision = precision_score(y_val, y_val_pred)\n",
        "val_recall = recall_score(y_val, y_val_pred)\n",
        "val_f1 = f1_score(y_val, y_val_pred)\n",
        "val_auc = roc_auc_score(y_val, xgboost_model.predict_proba(X_val_scaled)[:, 1])\n",
        "\n",
        "test_precision = precision_score(y_test, y_test_pred)\n",
        "test_recall = recall_score(y_test, y_test_pred)\n",
        "test_f1 = f1_score(y_test, y_test_pred)\n",
        "test_auc = roc_auc_score(y_test, xgboost_model.predict_proba(X_test_scaled)[:, 1])\n",
        "\n",
        "# Print the evaluation metrics\n",
        "print(f\"XGBoost Model Evaluation (Validation Set):\")\n",
        "print(f\"Validation Precision: {val_precision:.4f} | Validation Recall: {val_recall:.4f}\")\n",
        "print(f\"Validation F1-Score: {val_f1:.4f} | Validation AUC: {val_auc:.4f}\")\n",
        "\n",
        "print(f\"\\nXGBoost Model Evaluation (Test Set):\")\n",
        "print(f\"Test Precision: {test_precision:.4f} | Test Recall: {test_recall:.4f}\")\n",
        "print(f\"Test F1-Score: {test_f1:.4f} | Test AUC: {test_auc:.4f}\")\n",
        "\n",
        "print(f\"\\nTraining Time: {training_time:.4f} seconds\")\n"
      ],
      "metadata": {
        "id": "SRRCjGpcgcEf",
        "outputId": "5c8c9415-95b4-413f-97f6-29a41a892346",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "XGBoost Model Evaluation (Validation Set):\n",
            "Validation Precision: 0.6000 | Validation Recall: 0.5000\n",
            "Validation F1-Score: 0.5455 | Validation AUC: 0.5556\n",
            "\n",
            "XGBoost Model Evaluation (Test Set):\n",
            "Test Precision: 0.2000 | Test Recall: 0.1667\n",
            "Test F1-Score: 0.1818 | Test AUC: 0.3750\n",
            "\n",
            "Training Time: 0.0725 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Implementing"
      ],
      "metadata": {
        "id": "trCnfvrqhGK4"
      }
    }
  ]
}